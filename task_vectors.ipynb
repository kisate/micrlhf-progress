{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "filename = \"models/phi-3-16.gguf\"\n",
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(filename, device_map=\"auto\")\n",
    "from micrlhf.sampling import sample\n",
    "from transformers import AutoTokenizer\n",
    "import jax\n",
    "# tokenizer = load_tokenizer(filename)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'data/itv' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/.pyenv/versions/3.12.3/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/roeehendel/icl_task_vectors data/itv\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "tasks = {}\n",
    "for g in glob.glob(\"data/itv/data/**/*.json\"):\n",
    "    tasks[os.path.basename(g).partition(\".\")[0]] = json.load(open(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_b7695aa0962d4894a7e88f894654ac3e\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_b86614037b8d4ec9af73d6c541f2f838\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_b86614037b8d4ec9af73d6c541f2f838\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_b7695aa0962d4894a7e88f894654ac3e\"><script> (()=>{ const output = document.getElementById(\"output_b7695aa0962d4894a7e88f894654ac3e\"); const dest = document.getElementById(\"output_dest_b7695aa0962d4894a7e88f894654ac3e\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "dict_keys(['location_continent', 'football_player_position', 'location_religion', 'location_language', 'person_profession', 'location_country', 'country_capital', 'person_language', 'singular_plural', 'present_simple_past_simple', 'antonyms', 'plural_singular', 'present_simple_past_perfect', 'present_simple_gerund', 'en_it', 'it_en', 'en_fr', 'en_es', 'fr_en', 'es_en'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaBlock\n",
    "from micrlhf.sampling import sample, jit_wrapper\n",
    "get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "    pz.nn.Sequential([\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "        x\n",
    "    ])\n",
    ")\n",
    "get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "get_resids_call = jit_wrapper.Jitted(get_resids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import random\n",
    "from penzai.data_effects.side_output import SideOutputValue\n",
    "from micrlhf.utils.activation_manipulation import add_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple-representation of the sequence:\n",
      "(hot, cold), (yes, no), (in, out), up ->\n",
      "\n",
      "Actual prompt, which will be fed into the model:\n",
      "hot -> cold\n",
      "yes -> no\n",
      "in -> out\n",
      "up ->\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class ICLSequence:\n",
    "    '''\n",
    "    Class to store a single antonym sequence.\n",
    "\n",
    "    Uses the default template \"Q: {x}\\nA: {y}\" (with separate pairs split by \"\\n\\n\").\n",
    "    '''\n",
    "    def __init__(self, word_pairs: List[List[str]]):\n",
    "        self.word_pairs = word_pairs\n",
    "        self.x, self.y = zip(*word_pairs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.word_pairs[idx]\n",
    "\n",
    "    # def prompt(self):\n",
    "    #     '''Returns the prompt, which contains all but the second element in the last word pair.'''\n",
    "    #     p = \"\\n\\n\".join([f\"Q: {x}\\nA: {y}\" for x, y in self.word_pairs])\n",
    "    #     return p[:-len(self.completion())]\n",
    "\n",
    "    def prompt(self):\n",
    "        '''Returns the prompt, which contains all but the second element in the last word pair.'''\n",
    "        p = \"\\n\".join([f\"{x} -> {y}\" for x, y in self.word_pairs])\n",
    "        return p[:-len(self.completion())-1]\n",
    "\n",
    "    def completion(self):\n",
    "        '''Returns the second element in the last word pair (with padded space).'''\n",
    "        return \"\" + self.y[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        '''Prints a readable string representation of the prompt & completion (indep of template).'''\n",
    "        return f\"{', '.join([f'({x}, {y})' for x, y in self[:-1]])}, {self.x[-1]} ->\".strip(\", \")\n",
    "\n",
    "\n",
    "word_list = [[\"hot\", \"cold\"], [\"yes\", \"no\"], [\"in\", \"out\"], [\"up\", \"down\"]]\n",
    "seq = ICLSequence(word_list)\n",
    "\n",
    "print(\"Tuple-representation of the sequence:\")\n",
    "print(seq)\n",
    "print(\"\\nActual prompt, which will be fed into the model:\")\n",
    "print(seq.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLDataset:\n",
    "    '''\n",
    "    Dataset to create antonym pair prompts, in ICL task format. We use random seeds for consistency\n",
    "    between the corrupted and clean datasets.\n",
    "\n",
    "    Inputs:\n",
    "        word_pairs:\n",
    "            list of ICL task, e.g. [[\"old\", \"young\"], [\"top\", \"bottom\"], ...] for the antonym task\n",
    "        size:\n",
    "            number of prompts to generate\n",
    "        n_prepended:\n",
    "            number of antonym pairs before the single-word ICL task\n",
    "        bidirectional:\n",
    "            if True, then we also consider the reversed antonym pairs\n",
    "        corrupted:\n",
    "            if True, then the second word in each pair is replaced with a random word\n",
    "        seed:\n",
    "            random seed, for consistency & reproducibility\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        word_pairs: List[List[str]],\n",
    "        size: int,\n",
    "        n_prepended: int,\n",
    "        bidirectional: bool = True,\n",
    "        seed: int = 0,\n",
    "        corrupted: bool = False,\n",
    "    ):\n",
    "        assert n_prepended+1 <= len(word_pairs), \"Not enough antonym pairs in dataset to create prompt.\"\n",
    "\n",
    "        self.word_pairs = word_pairs\n",
    "        self.word_list = [word for word_pair in word_pairs for word in word_pair]\n",
    "        self.size = size\n",
    "        self.n_prepended = n_prepended\n",
    "        self.bidirectional = bidirectional\n",
    "        self.corrupted = corrupted\n",
    "        self.seed = seed\n",
    "\n",
    "        self.seqs = []\n",
    "        self.prompts = []\n",
    "        self.completions = []\n",
    "\n",
    "        # Generate the dataset (by choosing random antonym pairs, and constructing `ICLSequence` objects)\n",
    "        for n in range(size):\n",
    "            np.random.seed(seed + n)\n",
    "            random_pairs = np.random.choice(len(self.word_pairs), n_prepended+1, replace=False)\n",
    "            random_orders = np.random.choice([1, -1], n_prepended+1)\n",
    "            if not(bidirectional): random_orders[:] = 1\n",
    "            word_pairs = [self.word_pairs[pair][::order] for pair, order in zip(random_pairs, random_orders)]\n",
    "            if corrupted:\n",
    "                for i in range(len(word_pairs) - 1):\n",
    "                    word_pairs[i][1] = np.random.choice(self.word_list)\n",
    "            seq = ICLSequence(word_pairs)\n",
    "\n",
    "            self.seqs.append(seq)\n",
    "            self.prompts.append(seq.prompt())\n",
    "            self.completions.append(seq.completion())\n",
    "\n",
    "    def create_corrupted_dataset(self):\n",
    "        '''Creates a corrupted version of the dataset (with same random seed).'''\n",
    "        return ICLDataset(self.word_pairs, self.size, self.n_prepended, self.bidirectional, corrupted=True, seed=self.seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.seqs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_prompt(task, n_shots):\n",
    "    prompt = \"<user>Here is a rule:\\n{}\"\n",
    "    examples = []\n",
    "\n",
    "    for s, t in random.sample(list(tasks[task].items()), n_shots):\n",
    "        examples.append(f\"{s} -> {t}\")\n",
    "    prompt = prompt.format(\"\\n\".join(examples))\n",
    "\n",
    "    # print(prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def tokenized_to_inputs(input_ids, attention_mask):\n",
    "    token_array = jnp.asarray(input_ids)\n",
    "    token_array = jax.device_put(token_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "    token_array = pz.nx.wrap(token_array, \"batch\", \"seq\").untag(\"batch\").tag(\"batch\")\n",
    "\n",
    "    mask_array = jnp.asarray(attention_mask, dtype=jnp.bool)\n",
    "    mask_array = jax.device_put(mask_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "    mask_array = pz.nx.wrap(mask_array, \"batch\", \"seq\").untag(\"batch\").tag(\"batch\")\n",
    "\n",
    "    inputs = llama.inputs.from_basic_segments(token_array)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 381.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "datasets_dict = {}\n",
    "\n",
    "for task, pairs in tqdm(tasks.items()):\n",
    "  pairs = [list(x) for x in pairs.items()]\n",
    "  dataset = ICLDataset(pairs, size=20, n_prepended=10, bidirectional=False, seed=0)\n",
    "\n",
    "  prompts = dataset\n",
    "\n",
    "  # ld = logit_diff(dataset, model.run_with_saes(prompts, saes=[sae]))\n",
    "\n",
    "  # prompts_dict[task] = [x for x, y in zip(dataset.prompts, ld) if y >= -1e-6]\n",
    "  datasets_dict[task] = dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 430.87it/s]\n"
     ]
    }
   ],
   "source": [
    "zero_datasets_dict = {}\n",
    "\n",
    "for task, pairs in tqdm(tasks.items()):\n",
    "  pairs = [list(x) for x in pairs.items()]\n",
    "  dataset = ICLDataset(pairs, size=20, n_prepended=0, bidirectional=False, seed=1)\n",
    "\n",
    "  prompts = dataset\n",
    "\n",
    "  zero_datasets_dict[task] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_inputs_old(task, n_shots, batch_size, max_length=128, seed=0):\n",
    "    random.seed(seed)\n",
    "\n",
    "    texts = [generate_task_prompt(task, n_shots) for _ in range(batch_size)]\n",
    "    tokenized = tokenizer.batch_encode_plus(texts, padding=\"longest\", max_length=max_length, truncation=True, return_tensors=\"np\")\n",
    "\n",
    "    inputs = tokenized_to_inputs(\n",
    "        **tokenized\n",
    "    )\n",
    "\n",
    "    return inputs, tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logprob_diff_old(logits: jnp.ndarray, tokens: jnp.ndarray):\n",
    "    logprobs = jax.nn.log_softmax(logits, axis=-1)\n",
    "    \n",
    "    last_arrows = np.repeat(np.arange(tokens.shape[1])[None, :], tokens.shape[0], axis=0) * (tokens == 1599)\n",
    "    last_arrows = last_arrows.max(axis=-1)\n",
    "\n",
    "    answer_logprobs = jnp.take_along_axis(logprobs, last_arrows[:, None, None], axis=-1).squeeze()\n",
    "\n",
    "    target_tokens = jnp.take_along_axis(tokens, last_arrows[:, None], axis=-1).squeeze()\n",
    "    target_logprobs = jnp.take_along_axis(logprobs, target_tokens[:, None], axis=-1).squeeze()\n",
    "\n",
    "    return target_logprobs - answer_logprobs.max(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<user>Here is a rule:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, tokenized = generate_task_inputs_old(\"antonyms\", 20, 12, 128, seed=1)       \n",
    "logits, resids = get_resids_call(inputs)\n",
    "tokens = tokenized[\"input_ids\"]\n",
    "\n",
    "logits = logits.unwrap(\"batch\", \"seq\", \"vocabulary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: ICLDataset = datasets_dict[\"antonyms\"]\n",
    "tokenized = tokenizer.batch_encode_plus(dataset.prompts, padding=\"longest\", max_length=128, truncation=True, return_tensors=\"np\")\n",
    "inputs = tokenized_to_inputs(\n",
    "    **tokenized\n",
    ")\n",
    "\n",
    "logits, resids = get_resids_call(inputs)\n",
    "\n",
    "tokens = tokenized[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logprob_diff(logits: jnp.ndarray, completions: List[str], print_results=False):\n",
    "    logprobs = jax.nn.log_softmax(logits, axis=-1)\n",
    "    answer_logprobs = logprobs[:, -1]\n",
    "\n",
    "    target_tokens = [x[1] for x in tokenizer(completions)[\"input_ids\"]]\n",
    "    target_tokens = jnp.asarray(target_tokens)\n",
    "    target_logprobs = jnp.take_along_axis(answer_logprobs, target_tokens[:, None], axis=-1).squeeze()\n",
    "\n",
    "    if print_results:\n",
    "        print(\n",
    "            tokenizer.decode(answer_logprobs.argmax(axis=-1))\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            tokenizer.decode(target_tokens)\n",
    "        )\n",
    "\n",
    "    return target_logprobs - answer_logprobs.max(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost dead active far off fun small mismatch rural sharp weak h war retre cold wrong even stop bad rough\n",
      "lost dead active far off fun tiny sick rural sharp weak h war retre cold wrong even finish bad rough\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_f404302a62a74679b30a3c428ab0e455\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_de87ae35d4c247328592b6c420f100c5\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_de87ae35d4c247328592b6c420f100c5\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_4b76990fd2464cd28e3d477f32a11b44\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_4b76990fd2464cd28e3d477f32a11b44\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_f404302a62a74679b30a3c428ab0e455\"><script> (()=>{ const output = document.getElementById(\"output_f404302a62a74679b30a3c428ab0e455\"); const dest = document.getElementById(\"output_dest_f404302a62a74679b30a3c428ab0e455\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "<jax.Array bfloat16(20,) ≈-0.45 ±1.6 [≥-7.5, ≤0.0] zero:17 nonzero:3\n",
       "  <Arrayviz rendering>\n",
       "  Sharded across 4 TPU devices (click to expand)\n",
       ">"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "get_logprob_diff(logits.unwrap(\"batch\", \"seq\", \"vocabulary\"), dataset.completions, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee259783e984cb1bcf018723b77b136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost dead active far off fun small miss rural sharp weak h war retre cold left even stop bad rough\n",
      "lost dead active far off fun tiny sick rural sharp weak h war retre cold wrong even finish bad rough\n",
      "(220, 3072)\n",
      "-0.00166321 0.886719\n",
      "['lazy ->', 'old ->', 'pretty ->', 'heavy ->', 'cheap ->', 'deep ->', 'less ->', 'lazy ->', 'wild ->', 'bitter ->', 'cheap ->', 'hot ->', 'alive ->', 'horizontal ->', 'pro ->', 'proud ->', 'exit ->', 'divide ->', 'come ->', 'rare ->'] ['active', 'young', 'ugly', 'light', 'expensive', 'shallow', 'more', 'active', 'tame', 'sweet', 'expensive', 'cold', 'dead', 'vertical', 'con', 'humble', 'enter', 'unite', 'go', 'common']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lazy new ugly light expensive shall more lazy wild sweet expensive cold alive vertical positive happy exit divide go rare\n",
      "active young ugly light expensive shall more active t sweet expensive cold dead vertical con hum enter un go common\n",
      "lazy old pretty heavy cheap deep less lazy wild bitter cheap hot alive horizontal pro ar good / come r\n",
      "active young ugly light expensive shall more active t sweet expensive cold dead vertical con hum enter un go common\n",
      "orig: [[Array([0, 0, 0, 0, 0, 0, -0.875, -6.375, 0, 0, 0, 0, 0, 0, 0, -0.125, 0,\n",
      "       -2, 0, 0], dtype=bfloat16)], [Array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "        True,  True], dtype=bool)]]\n",
      "zero: [[Array([-6.125, -9.25, -2.3125, -3.125, -1.32031, -7.5625, -7.25, -6.125,\n",
      "       -5.125, -4.125, -1.32031, -6.5625, -1.25, -2.375, -6.875, -2.625,\n",
      "       -5, -8.0625, -6.3125, -10.6875], dtype=bfloat16)], [Array([False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False], dtype=bool)]]\n",
      "added: [[Array([-1, -0.246094, 0, 0, 0, 0, 0, -1, -3.14062, 0, 0, 0, -0.875, 0,\n",
      "       -3.3125, -0.375, -1.875, -5.25, 0, -1.875], dtype=bfloat16)], [Array([False, False,  True,  True,  True,  True,  True, False, False,\n",
      "        True,  True,  True, False,  True, False, False, False, False,\n",
      "        True, False], dtype=bool)]]\n",
      "orig: [-0.46875, 0.8]\n",
      "zero: [-5.15625, 0.0]\n",
      "added: [-0.945312, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_names = [\n",
    "    \"antonyms\"\n",
    "]\n",
    "layer = 16\n",
    "\n",
    "# n_few_shots, batch_size, max_seq_len = 64, 64, 512\n",
    "n_few_shots, batch_size, max_seq_len = 10, 20, 128\n",
    "for task in tqdm(task_names):\n",
    "    shot_logprobs_orig = [[] for _ in range(2)]\n",
    "    shot_logprobs_added = [[] for _ in range(2)]\n",
    "    shot_logprobs_zero = [[] for _ in range(2)]\n",
    "    for _ in trange(1):\n",
    "        pairs = tasks[task]\n",
    "        pairs = [list(x) for x in pairs.items()]\n",
    "        dataset = ICLDataset(pairs, size=batch_size, n_prepended=n_few_shots, bidirectional=False, seed=0)\n",
    "\n",
    "        tokenized = tokenizer.batch_encode_plus([prompt.format(x) for x in dataset.prompts], padding=\"longest\", max_length=max_seq_len, truncation=True, return_tensors=\"np\")\n",
    "        inputs = tokenized_to_inputs(\n",
    "            **tokenized\n",
    "        )\n",
    "        \n",
    "        logits, resids = get_resids_call(inputs)\n",
    "    \n",
    "        tokens = tokenized[\"input_ids\"]\n",
    "\n",
    "        shot_logprobs_orig[0].append(\n",
    "            get_logprob_diff(logits.unwrap(\"batch\", \"seq\", \"vocabulary\"), dataset.completions, print_results=True)\n",
    "        )\n",
    "\n",
    "        shot_logprobs_orig[1].append(\n",
    "            shot_logprobs_orig[0][-1] == 0.\n",
    "        )\n",
    "\n",
    "        mask = inputs.tokens == 1599\n",
    "        mask = mask.unwrap(\"batch\", \"seq\")\n",
    "\n",
    "        tv = resids[layer].value.unwrap(\"batch\", \"seq\", \"embedding\")[\n",
    "            mask\n",
    "        ]\n",
    "\n",
    "        tv = tv.mean(\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            tv.mean(), tv.std()\n",
    "        )\n",
    "\n",
    "        act_add = add_vector(\n",
    "            llama, tv, layer, scale=2.0, position=\"last\"\n",
    "        )\n",
    "\n",
    "        pairs = tasks[task]\n",
    "        pairs = [list(x) for x in pairs.items()]\n",
    "        dataset = ICLDataset(pairs, size=batch_size, n_prepended=0, bidirectional=False, seed=1)\n",
    "\n",
    "\n",
    "        print(\n",
    "            dataset.prompts, dataset.completions\n",
    "        )\n",
    "\n",
    "        tokenized = tokenizer.batch_encode_plus([prompt.format(x) for x in dataset.prompts], padding=\"longest\", max_length=max_seq_len, truncation=True, return_tensors=\"np\")\n",
    "        inputs = tokenized_to_inputs(\n",
    "            **tokenized\n",
    "        )\n",
    "\n",
    "        logits = act_add(inputs)\n",
    "\n",
    "        tokens = tokenized[\"input_ids\"]\n",
    "\n",
    "        shot_logprobs_added[0].append(\n",
    "            get_logprob_diff(logits.unwrap(\"batch\", \"seq\", \"vocabulary\"), dataset.completions, print_results=True)\n",
    "        )\n",
    "\n",
    "        shot_logprobs_added[1].append(\n",
    "            shot_logprobs_added[0][-1] == 0.\n",
    "        )\n",
    "\n",
    "        logits, _ = get_resids_call(inputs)\n",
    "        \n",
    "        shot_logprobs_zero[0].append(\n",
    "            get_logprob_diff(logits.unwrap(\"batch\", \"seq\", \"vocabulary\"), dataset.completions, print_results=True)\n",
    "        )\n",
    "\n",
    "        shot_logprobs_zero[1].append(\n",
    "            shot_logprobs_zero[0][-1] == 0.\n",
    "        )\n",
    "        \n",
    "    print(f\"orig: {shot_logprobs_orig}\")\n",
    "    print(f\"zero: {shot_logprobs_zero}\")\n",
    "    print(f\"added: {shot_logprobs_added}\")\n",
    "\n",
    "\n",
    "    shot_logprobs_orig = list(map(np.mean, shot_logprobs_orig))\n",
    "    shot_logprobs_zero = list(map(np.mean, shot_logprobs_zero))\n",
    "    shot_logprobs_added = list(map(np.mean, shot_logprobs_added))\n",
    "\n",
    "\n",
    "print(f\"orig: {shot_logprobs_orig}\")\n",
    "print(f\"zero: {shot_logprobs_zero}\")\n",
    "print(f\"added: {shot_logprobs_added}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
