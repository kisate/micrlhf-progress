{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mem usage: 0.0 GB out of 128 GB\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "\n",
    "def shmoogle_smi():\n",
    "    jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    pprof_path = \"/usr/local/go/pkg/tool/linux_amd64/pprof\"\n",
    "    out = subprocess.run([pprof_path, \"-top\", \"memory.prof\"], stdout=subprocess.PIPE)\n",
    "    stdout = out.stdout.decode(\"utf-8\")\n",
    "    re_sult = re.search(\n",
    "        r\"Showing nodes accounting for (\\d+(?:\\.\\d+)?)([MG]B)?, (\\d+(?:\\.\\d+)?)% of (\\d+(?:\\.\\d+)?)([MG]B)? total\",\n",
    "        stdout,\n",
    "    )\n",
    "    multiplier = 1 / 1000 if re_sult.group(5) == \"MB\" else 1\n",
    "    total_mem_usage = float(re_sult.group(4))\n",
    "    print(\n",
    "        \"Total mem usage:\",\n",
    "        total_mem_usage * multiplier,\n",
    "        \"GB\",\n",
    "        \"out of\",\n",
    "        16 * len(jax.devices()),\n",
    "        \"GB\",\n",
    "    )\n",
    "\n",
    "\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "from llama2_model import LLaMA\n",
    "\n",
    "import equinox as eqx\n",
    "import re\n",
    "from safetensors import safe_open\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
    "import jax.numpy as jnp\n",
    "import transformers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 15043, 3186, 29991]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\"models/Llama-2-7b-hf/tokenizer.model\")\n",
    "input_ids = tokenizer.encode(\"Hello world!\", bos=True, eos=False)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LLaMA...\n",
      "Created LLaMA.\n",
      "Total mem usage: 34.41 GB out of 128 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    }
   ],
   "source": [
    "num_devices = len(jax.devices())\n",
    "mesh = Mesh(np.array(jax.devices()).reshape(-1, 4), axis_names=(\"dp\", \"mp\"))\n",
    "policy = jmp.get_policy(\"p=bf16,c=bf16\")\n",
    "print(\"Creating LLaMA...\")\n",
    "llama = LLaMA(mesh, policy)\n",
    "print(\"Created LLaMA.\")\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "Loading model.embed_tokens.weight                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.norm.weight                                                       \n",
      "Total mem usage: 34.41 GB out of 128 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "print()\n",
    "for filename in [\n",
    "    \"models/Llama-2-7b-hf/model-00001-of-00002.safetensors\",\n",
    "    \"models/Llama-2-7b-hf/model-00002-of-00002.safetensors\",\n",
    "]:\n",
    "    with safe_open(\n",
    "        filename,\n",
    "        framework=\"numpy\",\n",
    "        device=\"cpu\",\n",
    "    ) as f:\n",
    "        for k in f.keys():\n",
    "            weight = f.get_tensor(k)\n",
    "            if (\n",
    "                k.endswith(\".weight\")\n",
    "                and not k.endswith(\"embed_tokens.weight\")\n",
    "                and not k.endswith(\"norm.weight\")\n",
    "                # and not k.endswith(\"lm_head.weight\")\n",
    "            ):\n",
    "                weight = weight.T\n",
    "            re_sult = re.search(r\"layers\\.([0-9]+)\", k)\n",
    "            try:\n",
    "                k = (\n",
    "                    k[: re_sult.span()[0]]\n",
    "                    + f\"layers[{re_sult.group(1)}]\"\n",
    "                    + k[re_sult.span()[1] :]\n",
    "                )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            print(\"\\r\" + \" \" * 80, end=\"\")\n",
    "            print(\"\\rLoading\", k, end=\"\")\n",
    "            og = eval(f\"llama.{k}\")\n",
    "            weight = jax.device_put(weight.astype(og.dtype), device=og.sharding)\n",
    "            llama = eval(f\"eqx.tree_at(lambda l: l.{k}, llama, weight)\")\n",
    "print()\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mem usage: 30.06 GB out of 128 GB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for //: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/micrlhf/main.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m ids \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(input_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m ids \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mdevice_put(ids, NamedSharding(mesh, spec\u001b[39m=\u001b[39mPartitionSpec(\u001b[39m\"\u001b[39m\u001b[39mdp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m result \u001b[39m=\u001b[39m llama_debug(ids)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[1;32m/home/neverix/micrlhf/main.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_model\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     weight, model \u001b[39m=\u001b[39m eqx\u001b[39m.\u001b[39mpartition(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m         base_model,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m             x, (jax\u001b[39m.\u001b[39mArray, jmp\u001b[39m.\u001b[39mPolicy, \u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39marray)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m         ),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     logs \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     model \u001b[39m=\u001b[39m tree_mlm(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m path, leaf: DebugWrapper(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m, path)), leaf, logs), model\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_module.py:345\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 345\u001b[0m     \u001b[39mreturn\u001b[39;00m tree_pformat(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:223\u001b[0m, in \u001b[0;36mtree_pformat\u001b[0;34m(pytree, width, indent, short_arrays, follow_wrapped, truncate_leaf)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_pformat\u001b[39m(\n\u001b[1;32m    209\u001b[0m     pytree: PrettyPrintAble,\n\u001b[1;32m    210\u001b[0m     width: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m80\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     truncate_leaf: Callable[[PrettyPrintAble], \u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m _false,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    216\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pretty-formats a PyTree as a string, whilst abbreviating JAX arrays.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[39m    (This is the function used in `__repr__` of [`equinox.Module`][].)\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39m    As [`equinox.tree_pprint`][], but returns the string instead of printing it.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m tree_pp(\n\u001b[1;32m    224\u001b[0m         pytree,\n\u001b[1;32m    225\u001b[0m         indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    226\u001b[0m         short_arrays\u001b[39m=\u001b[39;49mshort_arrays,\n\u001b[1;32m    227\u001b[0m         follow_wrapped\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[1;32m    228\u001b[0m         truncate_leaf\u001b[39m=\u001b[39;49mtruncate_leaf,\n\u001b[1;32m    229\u001b[0m     )\u001b[39m.\u001b[39mformat(width\u001b[39m=\u001b[39mwidth)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:175\u001b[0m, in \u001b[0;36mtree_pp\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[39mreturn\u001b[39;00m pp\u001b[39m.\u001b[39mgroup(custom_pp)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m dataclasses\u001b[39m.\u001b[39mis_dataclass(obj) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtype\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dataclass(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_list(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:136\u001b[0m, in \u001b[0;36m_pformat_dataclass\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_dataclass\u001b[39m(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# <uninitialised> can happen when typechecking an `eqx.Module`'s `__init__` method\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# with beartype, and printing args using pytest. We haven't yet actually assigned\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# values to the module so the repr fails.\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     objs \u001b[39m=\u001b[39m named_objs(\n\u001b[1;32m    137\u001b[0m         [\n\u001b[1;32m    138\u001b[0m             (field\u001b[39m.\u001b[39;49mname, \u001b[39mgetattr\u001b[39;49m(obj, field\u001b[39m.\u001b[39;49mname, \u001b[39m\"\u001b[39;49m\u001b[39m<uninitialised>\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    139\u001b[0m             \u001b[39mfor\u001b[39;49;00m field \u001b[39min\u001b[39;49;00m dataclasses\u001b[39m.\u001b[39;49mfields(obj)\n\u001b[1;32m    140\u001b[0m             \u001b[39mif\u001b[39;49;00m field\u001b[39m.\u001b[39;49mrepr\n\u001b[1;32m    141\u001b[0m         ],\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m    145\u001b[0m         name\u001b[39m=\u001b[39mpp\u001b[39m.\u001b[39mtext(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[1;32m    146\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:45\u001b[0m, in \u001b[0;36mnamed_objs\u001b[0;34m(pairs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m---> 46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:175\u001b[0m, in \u001b[0;36mtree_pp\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[39mreturn\u001b[39;00m pp\u001b[39m.\u001b[39mgroup(custom_pp)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m dataclasses\u001b[39m.\u001b[39mis_dataclass(obj) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtype\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dataclass(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_list(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:136\u001b[0m, in \u001b[0;36m_pformat_dataclass\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_dataclass\u001b[39m(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# <uninitialised> can happen when typechecking an `eqx.Module`'s `__init__` method\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# with beartype, and printing args using pytest. We haven't yet actually assigned\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# values to the module so the repr fails.\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     objs \u001b[39m=\u001b[39m named_objs(\n\u001b[1;32m    137\u001b[0m         [\n\u001b[1;32m    138\u001b[0m             (field\u001b[39m.\u001b[39;49mname, \u001b[39mgetattr\u001b[39;49m(obj, field\u001b[39m.\u001b[39;49mname, \u001b[39m\"\u001b[39;49m\u001b[39m<uninitialised>\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    139\u001b[0m             \u001b[39mfor\u001b[39;49;00m field \u001b[39min\u001b[39;49;00m dataclasses\u001b[39m.\u001b[39;49mfields(obj)\n\u001b[1;32m    140\u001b[0m             \u001b[39mif\u001b[39;49;00m field\u001b[39m.\u001b[39;49mrepr\n\u001b[1;32m    141\u001b[0m         ],\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m    145\u001b[0m         name\u001b[39m=\u001b[39mpp\u001b[39m.\u001b[39mtext(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[1;32m    146\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:45\u001b[0m, in \u001b[0;36mnamed_objs\u001b[0;34m(pairs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m---> 46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:177\u001b[0m, in \u001b[0;36mtree_pp\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dataclass(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_list(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    178\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dict(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:55\u001b[0m, in \u001b[0;36m_pformat_list\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_list\u001b[39m(obj: \u001b[39mlist\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m     53\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m---> 55\u001b[0m         objs\u001b[39m=\u001b[39m[tree_pp(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m obj],\n\u001b[1;32m     56\u001b[0m         lbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_list\u001b[39m(obj: \u001b[39mlist\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m     53\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m---> 55\u001b[0m         objs\u001b[39m=\u001b[39m[tree_pp(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m obj],\n\u001b[1;32m     56\u001b[0m         lbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:175\u001b[0m, in \u001b[0;36mtree_pp\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[39mreturn\u001b[39;00m pp\u001b[39m.\u001b[39mgroup(custom_pp)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m dataclasses\u001b[39m.\u001b[39mis_dataclass(obj) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtype\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dataclass(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_list(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:136\u001b[0m, in \u001b[0;36m_pformat_dataclass\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_dataclass\u001b[39m(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# <uninitialised> can happen when typechecking an `eqx.Module`'s `__init__` method\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# with beartype, and printing args using pytest. We haven't yet actually assigned\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# values to the module so the repr fails.\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     objs \u001b[39m=\u001b[39m named_objs(\n\u001b[1;32m    137\u001b[0m         [\n\u001b[1;32m    138\u001b[0m             (field\u001b[39m.\u001b[39;49mname, \u001b[39mgetattr\u001b[39;49m(obj, field\u001b[39m.\u001b[39;49mname, \u001b[39m\"\u001b[39;49m\u001b[39m<uninitialised>\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    139\u001b[0m             \u001b[39mfor\u001b[39;49;00m field \u001b[39min\u001b[39;49;00m dataclasses\u001b[39m.\u001b[39;49mfields(obj)\n\u001b[1;32m    140\u001b[0m             \u001b[39mif\u001b[39;49;00m field\u001b[39m.\u001b[39;49mrepr\n\u001b[1;32m    141\u001b[0m         ],\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m    145\u001b[0m         name\u001b[39m=\u001b[39mpp\u001b[39m.\u001b[39mtext(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[1;32m    146\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:45\u001b[0m, in \u001b[0;36mnamed_objs\u001b[0;34m(pairs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_objs\u001b[39m(pairs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m---> 46\u001b[0m         pp\u001b[39m.\u001b[39mconcat([pp\u001b[39m.\u001b[39mtext(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m), tree_pp(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)])\n\u001b[1;32m     47\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pairs\n\u001b[1;32m     48\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:175\u001b[0m, in \u001b[0;36mtree_pp\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[39mreturn\u001b[39;00m pp\u001b[39m.\u001b[39mgroup(custom_pp)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m dataclasses\u001b[39m.\u001b[39mis_dataclass(obj) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtype\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_dataclass(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m _pformat_list(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:137\u001b[0m, in \u001b[0;36m_pformat_dataclass\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_dataclass\u001b[39m(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# <uninitialised> can happen when typechecking an `eqx.Module`'s `__init__` method\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# with beartype, and printing args using pytest. We haven't yet actually assigned\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# values to the module so the repr fails.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     objs \u001b[39m=\u001b[39m named_objs(\n\u001b[0;32m--> 137\u001b[0m         [\n\u001b[1;32m    138\u001b[0m             (field\u001b[39m.\u001b[39mname, \u001b[39mgetattr\u001b[39m(obj, field\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39m<uninitialised>\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    139\u001b[0m             \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m dataclasses\u001b[39m.\u001b[39mfields(obj)\n\u001b[1;32m    140\u001b[0m             \u001b[39mif\u001b[39;00m field\u001b[39m.\u001b[39mrepr\n\u001b[1;32m    141\u001b[0m         ],\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m    145\u001b[0m         name\u001b[39m=\u001b[39mpp\u001b[39m.\u001b[39mtext(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[1;32m    146\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/equinox/_pretty_print.py:138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pformat_dataclass\u001b[39m(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pp\u001b[39m.\u001b[39mDoc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# <uninitialised> can happen when typechecking an `eqx.Module`'s `__init__` method\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# with beartype, and printing args using pytest. We haven't yet actually assigned\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# values to the module so the repr fails.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     objs \u001b[39m=\u001b[39m named_objs(\n\u001b[1;32m    137\u001b[0m         [\n\u001b[0;32m--> 138\u001b[0m             (field\u001b[39m.\u001b[39mname, \u001b[39mgetattr\u001b[39;49m(obj, field\u001b[39m.\u001b[39;49mname, \u001b[39m\"\u001b[39;49m\u001b[39m<uninitialised>\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    139\u001b[0m             \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m dataclasses\u001b[39m.\u001b[39mfields(obj)\n\u001b[1;32m    140\u001b[0m             \u001b[39mif\u001b[39;00m field\u001b[39m.\u001b[39mrepr\n\u001b[1;32m    141\u001b[0m         ],\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m bracketed(\n\u001b[1;32m    145\u001b[0m         name\u001b[39m=\u001b[39mpp\u001b[39m.\u001b[39mtext(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[1;32m    146\u001b[0m         indent\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mindent\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         rbracket\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/micrlhf/llama2_model.py:207\u001b[0m, in \u001b[0;36mSelfAttention._group_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_group_size\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_attention_heads \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_key_value_heads\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class WithPath:\n",
    "    path: tuple\n",
    "    value: object\n",
    "\n",
    "\n",
    "class DebugWrapper(eqx.Module):\n",
    "    name: str\n",
    "    module: eqx.Module\n",
    "\n",
    "    def __init__(self, name, module, write_to):\n",
    "        self.name = name\n",
    "        self.module = module\n",
    "        self.write_to = write_to\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        jax.debug.print(f\"Module called: {self.name} ({type(self.module)})\")\n",
    "        for arg in args:\n",
    "            if isinstance(arg, jax.Array):\n",
    "                print(\"Input:\", arg.shape, arg.dtype, str(arg)[:100])\n",
    "        result = self.module(*args, **kwargs)\n",
    "        self.write_to[self.name] = result\n",
    "        return result\n",
    "\n",
    "\n",
    "# short for multi-level map\n",
    "def tree_mlm(fn, tree):\n",
    "    all_leaves = []\n",
    "    new_tree = tree\n",
    "    while True:\n",
    "        leaves, tree_def = jax.tree_util.tree_flatten_with_path(\n",
    "            tree, is_leaf=lambda x: x not in all_leaves\n",
    "        )\n",
    "        if not leaves:\n",
    "            break\n",
    "        new_leaves = [fn(path, leaf) for path, leaf in leaves]\n",
    "        all_leaves.extend(new_leaves)\n",
    "        new_tree = jax.tree_util.tree_unflatten(tree_def, new_leaves)\n",
    "    return new_tree\n",
    "\n",
    "\n",
    "def debugify_model(model):\n",
    "    def new_model(*args, **kwargs):\n",
    "        weight, model = eqx.partition(\n",
    "            model,\n",
    "            lambda x: isinstance(\n",
    "                x, (jax.Array, jmp.Policy, int, float, bool, str, np.array)\n",
    "            ),\n",
    "        )\n",
    "        model = tree_mlm(\n",
    "            lambda path, leaf: DebugWrapper(\"\".join(map(str, path)), leaf), model\n",
    "        )\n",
    "        debug = eqx.combine(weight, model)\n",
    "        return debug(*args, **kwargs)\n",
    "    return new_model\n",
    "\n",
    "llama_debug = jax.vmap(debugify_model(llama))\n",
    "shmoogle_smi()\n",
    "\n",
    "with mesh:\n",
    "    input_ids = [\n",
    "        tokenizer.encode(x, bos=True, eos=False)\n",
    "        for x in [\"Hello world\", \"This is a test\"]\n",
    "    ]\n",
    "    input_ids = [x + [0] * (128 - len(x)) for x in input_ids]\n",
    "    ids = jnp.asarray(input_ids)\n",
    "    ids = jax.device_put(ids, NamedSharding(mesh, spec=PartitionSpec(\"dp\", None)))\n",
    "    result = llama_debug(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "reference_llama = transformers.LlamaModel.from_pretrained(\"models/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module called: embed_tokens <class 'torch.nn.modules.sparse.Embedding'>\n",
      "Input: torch.Size([2, 128]) torch.int64 tensor([[    1, 15043,  3186,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0\n",
      "Output: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 1.8616e-03, -3.3722e-03,  3.9864e-04,  ..., -8.3008e-03,\n",
      "           2.5787e-03, -3.9368e-\n",
      "Module called: layers.0.input_layernorm <class 'transformers.models.llama.modeling_llama.LlamaRMSNorm'>\n",
      "Input: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 1.8616e-03, -3.3722e-03,  3.9864e-04,  ..., -8.3008e-03,\n",
      "           2.5787e-03, -3.9368e-\n",
      "Output: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 6.7356e-03, -5.5986e-03,  9.5712e-05,  ..., -1.0382e-02,\n",
      "           3.4557e-03, -2.9162e-\n",
      "Module called: layers.0.self_attn.q_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 6.7356e-03, -5.5986e-03,  9.5712e-05,  ..., -1.0382e-02,\n",
      "           3.4557e-03, -2.9162e-\n",
      "Output: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 1.1561e-01, -4.1347e-01,  7.6590e-01,  ..., -1.1394e-01,\n",
      "           6.2359e-01,  1.6259e-\n",
      "Module called: layers.0.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 6.7356e-03, -5.5986e-03,  9.5712e-05,  ..., -1.0382e-02,\n",
      "           3.4557e-03, -2.9162e-\n",
      "Output: torch.Size([2, 128, 4096]) torch.float32 tensor([[[-4.5098e-01, -1.6371e-02,  4.9824e-02,  ...,  7.0969e-01,\n",
      "           2.1830e-01,  2.7735e-\n",
      "Module called: layers.0.self_attn.v_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: torch.Size([2, 128, 4096]) torch.float32 tensor([[[ 6.7356e-03, -5.5986e-03,  9.5712e-05,  ..., -1.0382e-02,\n",
      "           3.4557e-03, -2.9162e-\n",
      "Output: torch.Size([2, 128, 4096]) torch.float32 tensor([[[-6.0133e-03, -6.2898e-03,  5.6460e-03,  ...,  1.5145e-03,\n",
      "          -6.9511e-04, -1.4681e-\n",
      "Module called: layers.0.self_attn.rotary_emb <class 'transformers.models.llama.modeling_llama.LlamaRotaryEmbedding'>\n",
      "Input: torch.Size([2, 32, 128, 128]) torch.float32 tensor([[[[-6.0133e-03, -6.2898e-03,  5.6460e-03,  ...,  1.4103e-03,\n",
      "            2.0182e-02, -5.3975\n",
      "Output: torch.Size([128, 128]) torch.float32 tensor([[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5403,  0.6479,  0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/micrlhf/main.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     module\u001b[39m.\u001b[39mregister_forward_hook(make_torch_hook(name))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m input_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(input_ids)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B35.204.89.203/home/neverix/micrlhf/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m reference_llama(input_ids)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    923\u001b[0m         hidden_states,\n\u001b[1;32m    924\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    925\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    926\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    927\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    928\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    929\u001b[0m     )\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:672\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    671\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    673\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    674\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    675\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    676\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    677\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    678\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    679\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    680\u001b[0m )\n\u001b[1;32m    681\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    683\u001b[0m \u001b[39m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:377\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     kv_seq_len \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m past_key_value[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m--> 377\u001b[0m cos, sin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotary_emb(value_states, seq_len\u001b[39m=\u001b[39mkv_seq_len)\n\u001b[1;32m    378\u001b[0m query_states, key_states \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[39m# reuse k, v, self_attention\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def make_torch_hook(name):\n",
    "    def torch_hook(module, input, output):\n",
    "        print(f\"Module called: {name} {module.__class__}\")\n",
    "        for arg in input:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                print(\"Input:\", arg.shape, arg.dtype, str(arg)[:100])\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            print(\"Output:\", output.shape, output.dtype, str(output)[:100])\n",
    "        return output\n",
    "\n",
    "    return torch_hook\n",
    "\n",
    "\n",
    "for name, module in reference_llama.named_modules():\n",
    "    module._forward_hooks.clear()\n",
    "    module.register_forward_hook(make_torch_hook(name))\n",
    "\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "reference_llama(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
