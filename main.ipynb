{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mem usage: 0.0 GB out of 128 GB\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "\n",
    "def shmoogle_smi():\n",
    "    jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    pprof_path = \"/usr/local/go/pkg/tool/linux_amd64/pprof\"\n",
    "    out = subprocess.run([pprof_path, \"-top\", \"memory.prof\"], stdout=subprocess.PIPE)\n",
    "    stdout = out.stdout.decode(\"utf-8\")\n",
    "    re_sult = re.search(\n",
    "        r\"Showing nodes accounting for (\\d+(?:\\.\\d+)?)([MG]B)?, (\\d+(?:\\.\\d+)?)% of (\\d+(?:\\.\\d+)?)([MG]B)? total\",\n",
    "        stdout,\n",
    "    )\n",
    "    multiplier = 1 / 1000 if re_sult.group(5) == \"MB\" else 1\n",
    "    total_mem_usage = float(re_sult.group(4))\n",
    "    print(\n",
    "        \"Total mem usage:\",\n",
    "        total_mem_usage * multiplier,\n",
    "        \"GB\",\n",
    "        \"out of\",\n",
    "        16 * len(jax.devices()),\n",
    "        \"GB\",\n",
    "    )\n",
    "\n",
    "\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "from llama2_model import LLaMA\n",
    "\n",
    "import equinox as eqx\n",
    "import re\n",
    "from safetensors import safe_open\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
    "import jax.numpy as jnp\n",
    "import transformers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 15043, 3186, 29991]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\"models/Llama-2-7b-hf/tokenizer.model\")\n",
    "input_ids = tokenizer.encode(\"Hello world!\", bos=True, eos=False)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LLaMA...\n",
      "Created LLaMA.\n",
      "Total mem usage: 29.99 GB out of 128 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    }
   ],
   "source": [
    "num_devices = len(jax.devices())\n",
    "mesh = Mesh(np.array(jax.devices()).reshape(-1, 4), axis_names=(\"dp\", \"mp\"))\n",
    "policy = jmp.get_policy(\"p=bf16,c=bf16\")\n",
    "print(\"Creating LLaMA...\")\n",
    "llama = LLaMA(mesh, policy)\n",
    "print(\"Created LLaMA.\")\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "Loading model.embed_tokens.weight                                               \n",
      "model.embed_tokens.weight [[ 1.25169754e-06 -1.78813934e-06 -4.35113907e-06 ...  8.94069672e-07\n",
      "  -6.55651093e-06  8.94069672e-07]\n",
      " [ 1.86157227e-03 -3.37219238e-03  3.98635864e-04 ... -8.30078125e-03\n",
      "   2.57873535e-03 -3.93676758e-03]\n",
      " [ 1.09863281e-02  9.88769531e-03 -5.09643555e-03 ...  2.51770020e-03\n",
      "   7.70568848e-04 -5.00488281e-03]\n",
      " ...\n",
      " [-1.39770508e-02 -2.73132324e-03 -1.98974609e-02 ... -1.04370117e-02\n",
      "   9.58251953e-03 -1.80053711e-03]\n",
      " [-1.07421875e-02  9.33837891e-03  1.29394531e-02 ... -3.32031250e-02\n",
      "  -1.63574219e-02  3.38745117e-03]\n",
      " [-8.30078125e-03 -4.05883789e-03 -1.10626221e-03 ...  3.47900391e-03\n",
      "  -1.29394531e-02  3.19480896e-05]]\n",
      "\n",
      "Loading model.layers[0].input_layernorm.weight                                  \n",
      "model.layers[0].input_layernorm.weight [0.02966309 0.01361084 0.00196838 ... 0.01025391 0.01098633 0.006073  ]\n",
      "\n",
      "Loading model.layers[0].mlp.down_proj.weight                                    \n",
      "model.layers[0].mlp.down_proj.weight [[0.00270081 0.00460815 0.00204468 ... -0.0088501 -0.0177002 0.0119629]\n",
      " [-0.0144653 -0.00415039 0.0339355 ... -0.0114136 0.0373535 -0.00132751]\n",
      " [0.00830078 0.00897217 -0.00436401 ... 0.00515747 0.0090332 -0.00787354]\n",
      " ...\n",
      " [-0.0174561 0.0159912 -0.0146484 ... 0.0230713 -0.00692749 -0.000286102]\n",
      " [-0.00540161 -0.0137939 0.0219727 ... -0.0134888 -0.012207 -0.00296021]\n",
      " [0.00140381 0.0334473 0.0167236 ... 0.029541 -0.0218506 -0.0301514]]\n",
      "\n",
      "Loading model.layers[0].mlp.gate_proj.weight                                    \n",
      "model.layers[0].mlp.gate_proj.weight [[0.0157471 -0.00216675 0.00683594 ... 1.41263e-05 0.0266113 -0.000598907]\n",
      " [0.0170898 -0.00601196 -0.0216064 ... -0.0322266 0.0201416 -0.0113525]\n",
      " [0.0314941 0.00564575 0.0205078 ... 0.00579834 -0.0170898 -0.0236816]\n",
      " ...\n",
      " [-0.0158691 0.0161133 -0.0130005 ... -0.00891113 -0.00343323 0.00110626]\n",
      " [0.00650024 -0.00866699 0.0189209 ... -0.0134888 -0.00640869 0.00592041]\n",
      " [0.0158691 0.0098877 0.0194092 ... 0.0402832 -0.0189209 -0.0247803]]\n",
      "\n",
      "Loading model.layers[0].mlp.up_proj.weight                                      \n",
      "model.layers[0].mlp.up_proj.weight [[0.000267029 -0.0111084 -0.00592041 ... -0.00909424 -0.0166016 0.019043]\n",
      " [-0.0291748 -0.03125 0.0148926 ... -0.00164032 0.0072937 0.0196533]\n",
      " [0.0147705 0.0127563 -0.00842285 ... -0.00665283 0.0189209 -0.000425339]\n",
      " ...\n",
      " [-0.0209961 0.019043 -0.0227051 ... 0.029541 0.00139618 0.0118408]\n",
      " [-0.0269775 0.00604248 0.00750732 ... -0.00283813 -0.0166016 -0.0143433]\n",
      " [0.00653076 0.00247192 0.0017395 ... 0.0183105 0.00314331 -0.0388184]]\n",
      "\n",
      "Loading model.layers[0].post_attention_layernorm.weight                         \n",
      "model.layers[0].post_attention_layernorm.weight [0.05029297 0.05249023 0.05004883 ... 0.05249023 0.0534668  0.04907227]\n",
      "\n",
      "Loading model.layers[0].self_attn.k_proj.weight                                 \n",
      "model.layers[0].self_attn.k_proj.weight [[-0.0162354 0.019165 -0.0235596 ... 0.0127563 -0.00561523 0.00367737]\n",
      " [0.00787354 0.00154877 -0.0217285 ... -0.000724792 0.017334 -0.00210571]\n",
      " [-0.00126648 0.00364685 0.0016861 ... -0.000804901 -0.0032196 0.00128174]\n",
      " ...\n",
      " [0.0166016 -0.0211182 0.0150146 ... 0.000239372 -0.00323486 0.00698853]\n",
      " [-0.00994873 0.0151978 -0.0164795 ... 0.00305176 0.0114746 -0.0114746]\n",
      " [-0.0135498 0.0234375 -0.0117798 ... 0.00811768 -0.0110474 0.00946045]]\n",
      "\n",
      "Loading model.layers[0].self_attn.o_proj.weight                                 \n",
      "model.layers[0].self_attn.o_proj.weight [[-1.62125e-05 0.00276184 0.00233459 ... 0.00418091 -0.00335693\n",
      "  0.00619507]\n",
      " [-0.00192261 0.00184631 -0.000272751 ... -0.00332642 -0.00248718\n",
      "  -0.000656128]\n",
      " [0.00488281 -0.001297 0.000926971 ... 0.00588989 -0.00257874 0.00262451]\n",
      " ...\n",
      " [0.00592041 -0.00102997 -0.00165558 ... 0.00121307 0.00619507 0.00549316]\n",
      " [0.00344849 0.00180817 -0.0057373 ... 0.00260925 -0.003479 -0.00759888]\n",
      " [-0.00952148 0.0062561 -0.000637054 ... 0.00430298 -0.000511169\n",
      "  -0.00668335]]\n",
      "\n",
      "Loading model.layers[0].self_attn.q_proj.weight                                 \n",
      "model.layers[0].self_attn.q_proj.weight [[-0.00616455 0.0142212 -0.0145874 ... 0.00130463 0.0256348 -0.0134277]\n",
      " [-0.0147705 -0.0043335 0.0126343 ... 0.0108643 0.0101929 -0.00656128]\n",
      " [-0.00219727 0.0027771 0.000450134 ... -0.00034523 0.00320435 0.00183105]\n",
      " ...\n",
      " [0.00445557 -0.00933838 0.00628662 ... 0.00976562 -0.0334473 0.0180664]\n",
      " [0.00170135 -0.0114136 0.0187988 ... -0.0297852 -0.015625 0.0166016]\n",
      " [-0.00361633 0.00759888 -0.00312805 ... 0.00970459 -0.0123291\n",
      "  -0.00823975]]\n",
      "\n",
      "Loading model.layers[0].self_attn.rotary_emb.inv_freq                           \n",
      "model.layers[0].self_attn.rotary_emb.inv_freq [1.00000000e+00 8.65722656e-01 7.50000000e-01 6.49414062e-01\n",
      " 5.62500000e-01 4.87060547e-01 4.21630859e-01 3.65234375e-01\n",
      " 3.16162109e-01 2.73925781e-01 2.37182617e-01 2.05322266e-01\n",
      " 1.77856445e-01 1.54052734e-01 1.33300781e-01 1.15478516e-01\n",
      " 9.99755859e-02 8.66088867e-02 7.50122070e-02 6.49414062e-02\n",
      " 5.62438965e-02 4.87060547e-02 4.21752930e-02 3.65295410e-02\n",
      " 3.16162109e-02 2.73895264e-02 2.37121582e-02 2.05383301e-02\n",
      " 1.77764893e-02 1.53961182e-02 1.33361816e-02 1.15509033e-02\n",
      " 1.00021362e-02 8.65936279e-03 7.49969482e-03 6.49261475e-03\n",
      " 5.62286377e-03 4.87136841e-03 4.21524048e-03 3.65257263e-03\n",
      " 3.16238403e-03 2.73895264e-03 2.37083435e-03 2.05421448e-03\n",
      " 1.77860260e-03 1.54018402e-03 1.33323669e-03 1.15489960e-03\n",
      " 1.00040436e-03 8.65936279e-04 7.50064850e-04 6.49452209e-04\n",
      " 5.62191010e-04 4.86850739e-04 4.21762466e-04 3.65257263e-04\n",
      " 3.16143036e-04 2.73942947e-04 2.37107277e-04 2.05397606e-04\n",
      " 1.77860260e-04 1.54018402e-04 1.33395195e-04 1.15454197e-04]\n",
      "\n",
      "Loading model.layers[0].self_attn.v_proj.weight                                 \n",
      "model.layers[0].self_attn.v_proj.weight [[0.000785828 -0.00686646 0.00182343 ... -0.00631714 0.00305176\n",
      "  0.000135422]\n",
      " [-0.000595093 -0.000457764 0.00964355 ... -0.00570679 0.00479126\n",
      "  0.00253296]\n",
      " [0.00188446 -0.00772095 0.000999451 ... 0.0102539 -0.000976562 0.0055542]\n",
      " ...\n",
      " [0.00585938 -0.0106201 0.00479126 ... 0.00309753 0.00537109 -0.000686646]\n",
      " [-0.000602722 0.0125732 -0.013916 ... 0.0039978 0.015625 -0.000682831]\n",
      " [0.0103149 0.00476074 -0.0142212 ... -0.00224304 0.000701904 0.0014801]]\n",
      "\n",
      "Loading model.layers[1].input_layernorm.weight                                  \n",
      "model.layers[1].input_layernorm.weight [0.11376953 0.10986328 0.10058594 ... 0.06298828 0.09423828 0.07421875]\n",
      "\n",
      "Loading model.layers[1].mlp.down_proj.weight                                    \n",
      "model.layers[1].mlp.down_proj.weight [[0.00793457 0.0107422 -0.0170898 ... -0.0101929 -0.0129395 0.0244141]\n",
      " [0.00970459 0.00640869 -0.0146484 ... -0.00650024 0.0214844 -0.00379944]\n",
      " [0.0559082 -0.0358887 -0.0231934 ... -0.0162354 0.0148926 -0.0164795]\n",
      " ...\n",
      " [-0.0169678 0.00909424 -0.00141907 ... 0.0429688 -0.0299072 -0.0134888]\n",
      " [0.00238037 -0.0131836 -0.0106201 ... -0.00628662 -0.0189209 -0.0142212]\n",
      " [-0.0196533 0.00292969 0.00340271 ... 0.00738525 0.0233154 0.0297852]]\n",
      "\n",
      "Loading model.layers[1].mlp.gate_proj.weight                                    \n",
      "model.layers[1].mlp.gate_proj.weight [[0.0291748 -0.0280762 -0.006073 ... -0.0400391 -0.0161133 -0.0249023]\n",
      " [-0.00952148 -0.0018158 -0.0289307 ... 0.0163574 0.00364685 0.0145874]\n",
      " [0.0373535 -0.0314941 0.00312805 ... -0.00424194 -0.0373535 0.00546265]\n",
      " ...\n",
      " [-0.0339355 0.0144043 -0.00933838 ... -0.00159454 0.0206299 0.036377]\n",
      " [-0.0185547 -0.0218506 -0.0150757 ... 0.0144043 0.0195312 0.0098877]\n",
      " [-0.0112915 -0.0407715 -0.0211182 ... -0.00144958 -0.0120239 -0.034668]]\n",
      "\n",
      "Loading model.layers[1].mlp.up_proj.weight                                      \n",
      "model.layers[1].mlp.up_proj.weight [[0.00169373 0.00854492 0.027832 ... -0.0136719 0.0349121 -0.0158691]\n",
      " [0.0356445 -0.00228882 -0.0446777 ... -0.0270996 0.00152588 -0.0181885]\n",
      " [-0.0174561 -0.0133667 0.0128784 ... 0.0133057 -0.0167236 -0.00982666]\n",
      " ...\n",
      " [0.0115967 -0.00787354 0.0168457 ... 0.0256348 0.0043335 -0.0230713]\n",
      " [0.0301514 0.0100708 -0.0454102 ... 0.0106812 -0.00714111 -0.00747681]\n",
      " [-0.0177002 0.00952148 0.0289307 ... -0.0251465 -0.00123596 0.0218506]]\n",
      "\n",
      "Loading model.layers[1].post_attention_layernorm.weight                         \n",
      "model.layers[1].post_attention_layernorm.weight [0.09960938 0.10058594 0.09619141 ... 0.10742188 0.09960938 0.1015625 ]\n",
      "\n",
      "Loading model.layers[1].self_attn.k_proj.weight                                 \n",
      "model.layers[1].self_attn.k_proj.weight [[-0.0247803 -0.029541 -0.0250244 ... -0.0111084 0.00799561 -0.00799561]\n",
      " [-0.00250244 0.00457764 0.0294189 ... 0.0189209 -0.019165 0.0147095]\n",
      " [0.0383301 -0.0113525 -0.0649414 ... -0.00150299 0.0039978 0.000717163]\n",
      " ...\n",
      " [0.0179443 -0.0158691 0.0349121 ... 0.0109253 -0.012146 0.0039978]\n",
      " [0.020752 0.00939941 0.00787354 ... 6.07967e-05 -0.00146484 -0.00156403]\n",
      " [-0.00964355 -0.0588379 -0.0563965 ... 0.00671387 -0.00650024 0.00604248]]\n",
      "\n",
      "Loading model.layers[1].self_attn.o_proj.weight                                 \n",
      "model.layers[1].self_attn.o_proj.weight [[0.00482178 -0.00300598 0.0223389 ... 0.00331116 0.00218201 -0.0043335]\n",
      " [-0.0194092 -0.00543213 0.0125732 ... 0.00689697 -0.0125122 -0.0205078]\n",
      " [0.0142212 -0.0131836 -0.0119629 ... 0.00512695 0.0050354 0.00543213]\n",
      " ...\n",
      " [-0.00497437 -0.000743866 0.00473022 ... 0.000286102 -0.00215149\n",
      "  0.00128937]\n",
      " [-0.000128746 -0.00273132 0.0019989 ... 0.00222778 0.00183105\n",
      "  -0.00427246]\n",
      " [0.000274658 0.0032196 -0.00216675 ... -0.00193787 0.00210571 0.00191498]]\n",
      "\n",
      "Loading model.layers[1].self_attn.q_proj.weight                                 \n",
      "model.layers[1].self_attn.q_proj.weight [[-0.0125122 -0.000595093 0.0306396 ... -0.000177383 -0.00209045\n",
      "  0.000257492]\n",
      " [0.0072937 -0.00823975 0.0324707 ... 0.00180817 -0.00378418 0.00479126]\n",
      " [-0.0380859 0.00793457 0.0205078 ... 0.00360107 -0.00418091 0.00668335]\n",
      " ...\n",
      " [-0.00241089 -0.00830078 -0.000108719 ... -0.00866699 0.00878906\n",
      "  -0.00787354]\n",
      " [-0.0588379 -0.0488281 -0.074707 ... -0.00390625 0.00518799 -0.00050354]\n",
      " [0.0356445 0.02771 0.0229492 ... -0.00604248 0.00616455 -0.0111084]]\n",
      "\n",
      "Loading model.layers[1].self_attn.rotary_emb.inv_freq                           \n",
      "model.layers[1].self_attn.rotary_emb.inv_freq [1.00000000e+00 8.65722656e-01 7.50000000e-01 6.49414062e-01\n",
      " 5.62500000e-01 4.87060547e-01 4.21630859e-01 3.65234375e-01\n",
      " 3.16162109e-01 2.73925781e-01 2.37182617e-01 2.05322266e-01\n",
      " 1.77856445e-01 1.54052734e-01 1.33300781e-01 1.15478516e-01\n",
      " 9.99755859e-02 8.66088867e-02 7.50122070e-02 6.49414062e-02\n",
      " 5.62438965e-02 4.87060547e-02 4.21752930e-02 3.65295410e-02\n",
      " 3.16162109e-02 2.73895264e-02 2.37121582e-02 2.05383301e-02\n",
      " 1.77764893e-02 1.53961182e-02 1.33361816e-02 1.15509033e-02\n",
      " 1.00021362e-02 8.65936279e-03 7.49969482e-03 6.49261475e-03\n",
      " 5.62286377e-03 4.87136841e-03 4.21524048e-03 3.65257263e-03\n",
      " 3.16238403e-03 2.73895264e-03 2.37083435e-03 2.05421448e-03\n",
      " 1.77860260e-03 1.54018402e-03 1.33323669e-03 1.15489960e-03\n",
      " 1.00040436e-03 8.65936279e-04 7.50064850e-04 6.49452209e-04\n",
      " 5.62191010e-04 4.86850739e-04 4.21762466e-04 3.65257263e-04\n",
      " 3.16143036e-04 2.73942947e-04 2.37107277e-04 2.05397606e-04\n",
      " 1.77860260e-04 1.54018402e-04 1.33395195e-04 1.15454197e-04]\n",
      "\n",
      "Loading model.layers[1].self_attn.v_proj.weight                                 \n",
      "model.layers[1].self_attn.v_proj.weight [[0.00683594 -0.0035553 0.00592041 ... -0.00527954 -0.00628662\n",
      "  -0.00102234]\n",
      " [-0.00836182 0.00238037 -0.0118408 ... 0.00270081 -0.00558472 0.00164032]\n",
      " [-0.00408936 -0.00239563 0.0108643 ... 0.00463867 0.00939941 0.00415039]\n",
      " ...\n",
      " [-0.00613403 0.000778198 0.000413895 ... -0.00174713 -0.00805664\n",
      "  0.00187683]\n",
      " [-0.03125 0.0110474 -0.000938416 ... -0.000984192 0.00299072 -0.00579834]\n",
      " [-0.0262451 0.0332031 -0.0019455 ... 0.00148773 -0.0010376 0.00866699]]\n",
      "\n",
      "Loading model.layers[10].input_layernorm.weight                                 \n",
      "model.layers[10].input_layernorm.weight [0.36328125 0.359375   0.3203125  ... 0.33984375 0.34765625 0.3359375 ]\n",
      "\n",
      "Loading model.layers[10].mlp.down_proj.weight                                   \n",
      "model.layers[10].mlp.down_proj.weight [[-0.00976562 -0.0039978 -0.0322266 ... 0.0143433 -0.00222778 -0.048584]\n",
      " [-0.027832 0.0180664 -0.00204468 ... -0.00497437 0.0463867 -7.20024e-05]\n",
      " [-0.00402832 -0.00775146 0.0164795 ... 0.00265503 -0.0157471 -0.0281982]\n",
      " ...\n",
      " [0.0291748 -0.00860596 -0.0250244 ... 0.0149536 0.0177002 -0.0178223]\n",
      " [-0.0147705 0.0108032 -0.0252686 ... 0.0133057 0.0314941 -0.0145874]\n",
      " [-1.45435e-05 -0.000694275 0.00811768 ... 0.00765991 -0.0319824\n",
      "  0.0102539]]\n",
      "\n",
      "Loading model.layers[10].mlp.gate_proj.weight                                   \n",
      "model.layers[10].mlp.gate_proj.weight [[-0.0317383 -0.017334 -0.0157471 ... -0.046875 0.00595093 -0.00787354]\n",
      " [-0.0419922 -0.0147095 -0.0212402 ... -0.00233459 0.0195312 -0.0147705]\n",
      " [-0.0263672 -0.0137329 0.00915527 ... 0.0125122 0.019165 -0.020874]\n",
      " ...\n",
      " [-0.00518799 0.00292969 0.0303955 ... 0.00753784 0.00466919 -0.012146]\n",
      " [-0.00147247 0.0145264 -0.00350952 ... -0.0311279 -0.0115356 0.00338745]\n",
      " [-0.00970459 0.0166016 0.00115204 ... 0.0198975 -0.00318909 -0.0157471]]\n",
      "\n",
      "Loading model.layers[10].mlp.up_proj.weight                                     \n",
      "model.layers[10].mlp.up_proj.weight [[-0.0429688 -0.00726318 -0.000389099 ... 0.0219727 -0.0043335\n",
      "  -0.00204468]\n",
      " [-0.00325012 0.00970459 -0.00151825 ... 0.0213623 -0.00177765 0.0142822]\n",
      " [-0.0373535 0.00418091 0.0120239 ... -0.0011673 -0.027832 0.00338745]\n",
      " ...\n",
      " [0.0109253 0.0234375 0.024292 ... -0.0432129 0.020874 0.000320435]\n",
      " [-0.00817871 0.0366211 -0.032959 ... -0.00254822 -0.0152588 0.00765991]\n",
      " [-0.020874 -0.0137329 -0.00231934 ... -0.00163269 0.0142212 0.0153198]]\n",
      "\n",
      "Loading model.layers[10].post_attention_layernorm.weight                        \n",
      "model.layers[10].post_attention_layernorm.weight [0.24609375 0.23242188 0.22363281 ... 0.24023438 0.23730469 0.23730469]\n",
      "\n",
      "Loading model.layers[10].self_attn.k_proj.weight                                \n",
      "model.layers[10].self_attn.k_proj.weight [[-0.0223389 -0.0108032 -0.00509644 ... -0.0449219 -0.0371094 -0.0285645]\n",
      " [0.00744629 0.0072937 0.000938416 ... -0.0593262 -0.0072937 0.0267334]\n",
      " [-0.0055542 -0.00595093 0.00653076 ... 0.0078125 0.029541 -0.0212402]\n",
      " ...\n",
      " [-0.0101929 0.0105591 -0.0159912 ... 0.03125 -0.019165 0.015625]\n",
      " [0.00454712 -0.0120239 0.0230713 ... -0.078125 -0.0441895 0.0483398]\n",
      " [-0.0043335 0.00756836 -4.29153e-06 ... 0.00891113 -0.0222168\n",
      "  -0.00915527]]\n",
      "\n",
      "Loading model.layers[10].self_attn.o_proj.weight                                \n",
      "model.layers[10].self_attn.o_proj.weight [[-0.00297546 0.000961304 0.0131836 ... -0.001091 0.00543213 0.0090332]\n",
      " [0.00152588 -0.012146 -0.0361328 ... 0.0124512 -0.0123291 -0.0129395]\n",
      " [-0.0314941 0.0125732 -0.0200195 ... -0.012146 -0.0219727 -0.0256348]\n",
      " ...\n",
      " [-0.000541687 0.00350952 0.00848389 ... -0.00491333 0.0116577 0.0117798]\n",
      " [0.010376 0.0137939 -0.00939941 ... 0.00366211 0.0101318 -0.000347137]\n",
      " [0.00823975 0.00466919 -0.00552368 ... 0.0217285 0.00337219 0.00221252]]\n",
      "\n",
      "Loading model.layers[10].self_attn.q_proj.weight                                \n",
      "model.layers[10].self_attn.q_proj.weight [[-0.00141144 -0.00405884 -0.00994873 ... 0.032959 -0.059082 -0.0498047]\n",
      " [0.00482178 -0.00738525 -0.00860596 ... 0.0639648 0.0576172 -0.0216064]\n",
      " [-0.00164795 0.0166016 -0.00540161 ... -0.0151978 -0.000204086\n",
      "  -0.00497437]\n",
      " ...\n",
      " [0.0101929 -0.00601196 0.0203857 ... 0.0307617 -0.0683594 -0.00952148]\n",
      " [-0.00424194 0.0598145 -0.0153198 ... 0.0366211 -0.000686646 -0.0324707]\n",
      " [-0.00836182 8.72612e-05 -0.0170898 ... -0.00830078 -0.00805664\n",
      "  -0.0183105]]\n",
      "\n",
      "Loading model.layers[10].self_attn.rotary_emb.inv_freq                          \n",
      "model.layers[10].self_attn.rotary_emb.inv_freq [1.00000000e+00 8.65722656e-01 7.50000000e-01 6.49414062e-01\n",
      " 5.62500000e-01 4.87060547e-01 4.21630859e-01 3.65234375e-01\n",
      " 3.16162109e-01 2.73925781e-01 2.37182617e-01 2.05322266e-01\n",
      " 1.77856445e-01 1.54052734e-01 1.33300781e-01 1.15478516e-01\n",
      " 9.99755859e-02 8.66088867e-02 7.50122070e-02 6.49414062e-02\n",
      " 5.62438965e-02 4.87060547e-02 4.21752930e-02 3.65295410e-02\n",
      " 3.16162109e-02 2.73895264e-02 2.37121582e-02 2.05383301e-02\n",
      " 1.77764893e-02 1.53961182e-02 1.33361816e-02 1.15509033e-02\n",
      " 1.00021362e-02 8.65936279e-03 7.49969482e-03 6.49261475e-03\n",
      " 5.62286377e-03 4.87136841e-03 4.21524048e-03 3.65257263e-03\n",
      " 3.16238403e-03 2.73895264e-03 2.37083435e-03 2.05421448e-03\n",
      " 1.77860260e-03 1.54018402e-03 1.33323669e-03 1.15489960e-03\n",
      " 1.00040436e-03 8.65936279e-04 7.50064850e-04 6.49452209e-04\n",
      " 5.62191010e-04 4.86850739e-04 4.21762466e-04 3.65257263e-04\n",
      " 3.16143036e-04 2.73942947e-04 2.37107277e-04 2.05397606e-04\n",
      " 1.77860260e-04 1.54018402e-04 1.33395195e-04 1.15454197e-04]\n",
      "\n",
      "Loading model.layers[10].self_attn.v_proj.weight                                \n",
      "model.layers[10].self_attn.v_proj.weight [[-0.0400391 -0.00799561 0.0148926 ... 0.0230713 0.00248718 0.0143433]\n",
      " [0.003479 0.0132446 -0.0125122 ... 0.0290527 0.00775146 0.00872803]\n",
      " [-0.00650024 0.0123291 0.0151978 ... 0.000163078 0.000728607 -0.0152588]\n",
      " ...\n",
      " [0.0071106 -0.00775146 0.0155029 ... 0.0281982 0.00177765 -0.00463867]\n",
      " [0.0110474 -0.0388184 0.00646973 ... -0.00515747 0.0117188 -0.0125122]\n",
      " [0.0102539 0.0186768 -0.00448608 ... -0.0158691 0.000143051 0.0299072]]\n",
      "\n",
      "Loading model.layers[11].input_layernorm.weight                                 \n",
      "model.layers[11].input_layernorm.weight [0.39453125 0.39257812 0.359375   ... 0.3828125  0.37695312 0.3671875 ]\n",
      "\n",
      "Loading model.layers[11].mlp.down_proj.weight                                   \n",
      "model.layers[11].mlp.down_proj.weight [[-0.0198975 -0.0145264 -0.0200195 ... 0.0187988 -0.015564 0.0351562]\n",
      " [0.0456543 -0.0045166 -0.00897217 ... 0.0253906 -0.0299072 0.0194092]\n",
      " [0.0177002 -0.0256348 0.00683594 ... -0.0123901 -0.0308838 0.0222168]\n",
      " ...\n",
      " [0.0194092 -0.03125 0.00150299 ... 0.00176239 -0.0219727 0.0038147]\n",
      " [0.0145264 -0.00927734 -0.0186768 ... 0.00119019 -0.00576782 -0.0125122]\n",
      " [-0.00430298 0.0155029 -0.00631714 ... 0.00872803 0.0139771 0.0405273]]\n",
      "\n",
      "Loading model.layers[11].mlp.gate_proj.weight                                   \n",
      "model.layers[11].mlp.gate_proj.weight [[-0.0446777 0.00213623 -0.00219727 ... -0.0180664 0.0025177 -0.00769043]\n",
      " [-0.0100098 -0.0109253 -0.0441895 ... -0.0344238 0.00619507 0.0100708]\n",
      " [0.00166321 0.0234375 -0.0378418 ... -0.0189209 -0.0258789 0.0119629]\n",
      " ...\n",
      " [0.0038147 0.0109863 -0.000675201 ... -0.00405884 -0.0128174 0.0344238]\n",
      " [-0.00598145 -0.0185547 -0.00390625 ... -0.0281982 0.00970459 -0.0032196]\n",
      " [0.0380859 -0.043457 0.00338745 ... 0.00132751 0.000507355 -0.0184326]]\n",
      "\n",
      "Loading model.layers[11].mlp.up_proj.weight                                     \n",
      "model.layers[11].mlp.up_proj.weight [[-0.0101318 0.0155029 -0.0105591 ... 0.0422363 -0.0106812 0.00144958]\n",
      " [-0.00119019 0.00173187 -0.0290527 ... 0.0126343 0.00823975 -0.00241089]\n",
      " [-0.026001 -0.0186768 -0.00244141 ... -0.0035553 0.0100708 -0.00805664]\n",
      " ...\n",
      " [0.026001 0.00958252 -0.0088501 ... -0.0019455 0.0196533 -0.0143433]\n",
      " [0.00369263 -0.0410156 -0.0158691 ... 0.00196838 0.00756836 0.00579834]\n",
      " [0.0310059 0.00378418 0.0166016 ... 0.0196533 0.00668335 0.0264893]]\n",
      "\n",
      "Loading model.layers[11].post_attention_layernorm.weight                        \n",
      "model.layers[11].post_attention_layernorm.weight [0.25390625 0.23632812 0.23339844 ... 0.25       0.24902344 0.24511719]\n",
      "\n",
      "Loading model.layers[11].self_attn.k_proj.weight                                \n",
      "model.layers[11].self_attn.k_proj.weight [[0.00500488 -0.000255585 0.0147095 ... -0.00848389 0.0644531 0.00598145]\n",
      " [0.0186768 -0.00344849 -0.0253906 ... 0.0211182 -0.0107422 0.0055542]\n",
      " [-0.000858307 -0.0253906 0.0072937 ... 0.00250244 -0.0117798 0.0180664]\n",
      " ...\n",
      " [-0.0106201 -0.00793457 0.00720215 ... -0.019043 -0.00291443 -0.00476074]\n",
      " [0.00242615 -0.00460815 0.00521851 ... -0.0120239 0.00552368 0.0610352]\n",
      " [-0.0212402 0.0263672 0.00527954 ... 0.0305176 -0.00769043 0.024292]]\n",
      "\n",
      "Loading model.layers[11].self_attn.o_proj.weight                                \n",
      "model.layers[11].self_attn.o_proj.weight [[-0.0183105 0.00164795 -0.00772095 ... 0.00379944 0.00263977 -0.00340271]\n",
      " [-0.000801086 -0.026123 -0.00500488 ... -0.00521851 0.0217285\n",
      "  -0.00439453]\n",
      " [0.00518799 0.017334 0.0192871 ... 0.0231934 0.00958252 0.00193024]\n",
      " ...\n",
      " [0.00921631 -0.0119629 0.00102997 ... 0.00164032 0.0155029 -0.00588989]\n",
      " [0.0111694 0.00184631 -0.000182152 ... 0.00119019 0.0111084 0.00148773]\n",
      " [0.00149536 -0.0162354 0.019043 ... -0.00735474 -0.0317383 -0.0128784]]\n",
      "\n",
      "Loading model.layers[11].self_attn.q_proj.weight                                \n",
      "model.layers[11].self_attn.q_proj.weight [[0.0152588 -0.0131836 0.000850677 ... 0.000576019 0.0446777 0.0717773]\n",
      " [0.0164795 0.00909424 0.00631714 ... -0.00479126 0.0179443 -0.0206299]\n",
      " [-0.00698853 0.0111084 -0.0240479 ... 0.0324707 -0.0120239 -0.0213623]\n",
      " ...\n",
      " [0.0217285 0.0142212 -0.00202942 ... 0.0344238 -0.00823975 -0.0205078]\n",
      " [-0.0050354 0.0142212 -0.0103149 ... 0.0405273 0.0184326 0.0461426]\n",
      " [0.000276566 -0.000392914 0.00585938 ... -0.0301514 -0.0292969 0.057373]]\n",
      "\n",
      "Loading model.layers[11].self_attn.rotary_emb.inv_freq                          \n",
      "model.layers[11].self_attn.rotary_emb.inv_freq [1.00000000e+00 8.65722656e-01 7.50000000e-01 6.49414062e-01\n",
      " 5.62500000e-01 4.87060547e-01 4.21630859e-01 3.65234375e-01\n",
      " 3.16162109e-01 2.73925781e-01 2.37182617e-01 2.05322266e-01\n",
      " 1.77856445e-01 1.54052734e-01 1.33300781e-01 1.15478516e-01\n",
      " 9.99755859e-02 8.66088867e-02 7.50122070e-02 6.49414062e-02\n",
      " 5.62438965e-02 4.87060547e-02 4.21752930e-02 3.65295410e-02\n",
      " 3.16162109e-02 2.73895264e-02 2.37121582e-02 2.05383301e-02\n",
      " 1.77764893e-02 1.53961182e-02 1.33361816e-02 1.15509033e-02\n",
      " 1.00021362e-02 8.65936279e-03 7.49969482e-03 6.49261475e-03\n",
      " 5.62286377e-03 4.87136841e-03 4.21524048e-03 3.65257263e-03\n",
      " 3.16238403e-03 2.73895264e-03 2.37083435e-03 2.05421448e-03\n",
      " 1.77860260e-03 1.54018402e-03 1.33323669e-03 1.15489960e-03\n",
      " 1.00040436e-03 8.65936279e-04 7.50064850e-04 6.49452209e-04\n",
      " 5.62191010e-04 4.86850739e-04 4.21762466e-04 3.65257263e-04\n",
      " 3.16143036e-04 2.73942947e-04 2.37107277e-04 2.05397606e-04\n",
      " 1.77860260e-04 1.54018402e-04 1.33395195e-04 1.15454197e-04]\n",
      "\n",
      "Loading model.layers[11].self_attn.v_proj.weight                                \n",
      "model.layers[11].self_attn.v_proj.weight [[0.00500488 0.00230408 0.00248718 ... -0.0154419 -0.00830078 0.0130615]\n",
      " [0.00457764 -0.00653076 0.00692749 ... 0.00628662 0.0150146 -0.0228271]\n",
      " [-0.0101318 -0.012146 -0.00686646 ... -0.0140991 -0.0102539 0.00267029]\n",
      " ...\n",
      " [-0.019043 0.00662231 0.0147095 ... 0.00561523 -0.0144043 -0.0393066]\n",
      " [0.000740051 0.00564575 0.00463867 ... -0.0189209 -0.0172119 -0.00389099]\n",
      " [0.00592041 -0.024292 -0.0224609 ... -0.00230408 0.00335693 -0.0131226]]\n",
      "\n",
      "Loading model.layers[12].input_layernorm.weight                                 \n",
      "model.layers[12].input_layernorm.weight [0.40234375 0.3984375  0.36523438 ... 0.37890625 0.3828125  0.38476562]\n",
      "\n",
      "Loading model.layers[12].mlp.down_proj.weight                                   \n",
      "model.layers[12].mlp.down_proj.weight [[0.00454712 0.0169678 0.0146484 ... 0.0153809 -0.0249023 0.0057373]\n",
      " [-0.00674438 -0.0236816 0.00140381 ... -0.0127563 0.0137329 0.0203857]\n",
      " [-0.0317383 0.00164795 0.0179443 ... -0.0446777 0.0100098 0.0275879]\n",
      " ...\n",
      " [-0.0117188 -0.00860596 0.00598145 ... 0.0390625 -0.00622559 -0.0341797]\n",
      " [0.00344849 -0.0105591 -0.00891113 ... -0.0187988 0.0373535 0.0175781]\n",
      " [0.00726318 -0.0161133 -0.020752 ... -0.0169678 -0.0218506 -0.00254822]]\n",
      "\n",
      "Loading model.layers[12].mlp.gate_proj.weight                                   \n",
      "model.layers[12].mlp.gate_proj.weight [[0.00704956 -0.0250244 0.00506592 ... -0.000343323 -0.0349121 0.00227356]\n",
      " [-0.0255127 -0.0269775 0.0223389 ... 0.00872803 -0.00732422 -0.0185547]\n",
      " [0.0106812 0.0150757 -0.00561523 ... 0.0128174 0.00415039 -0.00717163]\n",
      " ...\n",
      " [-0.00442505 0.0155029 -0.00775146 ... -0.0244141 0.00674438 -0.00323486]\n",
      " [0.0211182 0.0162354 -0.0429688 ... -0.0010376 0.0105591 -0.00842285]\n",
      " [0.00668335 0.0145264 0.00154877 ... 0.0212402 -0.00274658 -0.015625]]\n",
      "\n",
      "Loading model.layers[12].mlp.up_proj.weight                                     \n",
      "model.layers[12].mlp.up_proj.weight [[0.00402832 -0.0030365 0.00878906 ... -0.0159912 0.00285339 -0.0119019]\n",
      " [0.0185547 -0.0132446 -0.00260925 ... -0.0341797 -0.0310059 -0.0170898]\n",
      " [0.00622559 -0.0105591 0.0119629 ... -0.00585938 -0.00332642 -0.00411987]\n",
      " ...\n",
      " [-0.0055542 0.00340271 -0.0463867 ... 0.0136719 0.0098877 0.0375977]\n",
      " [0.0172119 -0.0116577 0.0127563 ... -0.0186768 0.00787354 -0.00466919]\n",
      " [0.0169678 0.026001 0.00376892 ... 0.00442505 -0.012207 -0.0332031]]\n",
      "\n",
      "Loading model.layers[12].post_attention_layernorm.weight                        \n",
      "model.layers[12].post_attention_layernorm.weight [0.2578125  0.24414062 0.23730469 ... 0.25585938 0.25390625 0.25390625]\n",
      "\n",
      "Loading model.layers[12].self_attn.k_proj.weight                                \n",
      "model.layers[12].self_attn.k_proj.weight [[0.0117188 0.00393677 -0.00765991 ... 0.0152588 -0.0368652 0.000713348]\n",
      " [-0.00439453 0.0166016 -0.0195312 ... 0.0279541 0.0057373 0.0351562]\n",
      " [-0.00195312 -0.00805664 0.00698853 ... -0.0177002 0.0269775 0.00952148]\n",
      " ...\n",
      " [0.013855 0.0118408 0.0166016 ... -0.0390625 -0.0246582 0.013855]\n",
      " [0.00442505 -0.0151978 -0.00744629 ... -0.0155029 0.0195312 -0.0458984]\n",
      " [-0.0078125 -0.0196533 0.0155029 ... -0.0218506 -0.00215149 -0.032959]]\n",
      "\n",
      "Loading model.layers[12].self_attn.o_proj.weight                                \n",
      "model.layers[12].self_attn.o_proj.weight [[0.0272217 -0.00582886 0.00314331 ... 0.00254822 -0.012085 0.019165]\n",
      " [0.00674438 -0.0107422 -0.00524902 ... -0.00157928 -0.0344238 0.00631714]\n",
      " [-0.000713348 0.00144958 -0.00482178 ... 0.0136108 -0.0297852 0.010498]\n",
      " ...\n",
      " [0.00179291 -0.0136108 0.00564575 ... -0.0065918 -0.00543213 0.020752]\n",
      " [0.00787354 0.00488281 -0.0267334 ... -0.001091 0.00909424 -0.012146]\n",
      " [-0.00369263 -0.0187988 0.0125732 ... 0.00108337 0.0172119 -0.0175781]]\n",
      "\n",
      "Loading model.layers[12].self_attn.q_proj.weight                                \n",
      "model.layers[12].self_attn.q_proj.weight [[-0.00445557 0.00460815 0.00842285 ... -0.00411987 0.034668 0.0339355]\n",
      " [-0.0196533 0.00531006 0.0356445 ... 0.0385742 -0.00619507 0.0135498]\n",
      " [0.00946045 0.000694275 -0.0291748 ... -0.0206299 0.0108643 -0.0410156]\n",
      " ...\n",
      " [0.0189209 -0.0122681 0.00357056 ... -0.03125 0.0344238 -0.0178223]\n",
      " [-0.00546265 0.0262451 0.0137939 ... -0.00872803 0.0050354 0.0174561]\n",
      " [0.0078125 0.0163574 -0.0317383 ... 0.0113525 -0.0327148 0.0249023]]\n",
      "\n",
      "Loading model.layers[12].self_attn.rotary_emb.inv_freq                          \n",
      "model.layers[12].self_attn.rotary_emb.inv_freq [1.00000000e+00 8.65722656e-01 7.50000000e-01 6.49414062e-01\n",
      " 5.62500000e-01 4.87060547e-01 4.21630859e-01 3.65234375e-01\n",
      " 3.16162109e-01 2.73925781e-01 2.37182617e-01 2.05322266e-01\n",
      " 1.77856445e-01 1.54052734e-01 1.33300781e-01 1.15478516e-01\n",
      " 9.99755859e-02 8.66088867e-02 7.50122070e-02 6.49414062e-02\n",
      " 5.62438965e-02 4.87060547e-02 4.21752930e-02 3.65295410e-02\n",
      " 3.16162109e-02 2.73895264e-02 2.37121582e-02 2.05383301e-02\n",
      " 1.77764893e-02 1.53961182e-02 1.33361816e-02 1.15509033e-02\n",
      " 1.00021362e-02 8.65936279e-03 7.49969482e-03 6.49261475e-03\n",
      " 5.62286377e-03 4.87136841e-03 4.21524048e-03 3.65257263e-03\n",
      " 3.16238403e-03 2.73895264e-03 2.37083435e-03 2.05421448e-03\n",
      " 1.77860260e-03 1.54018402e-03 1.33323669e-03 1.15489960e-03\n",
      " 1.00040436e-03 8.65936279e-04 7.50064850e-04 6.49452209e-04\n",
      " 5.62191010e-04 4.86850739e-04 4.21762466e-04 3.65257263e-04\n",
      " 3.16143036e-04 2.73942947e-04 2.37107277e-04 2.05397606e-04\n",
      " 1.77860260e-04 1.54018402e-04 1.33395195e-04 1.15454197e-04]\n",
      "\n",
      "Loading model.layers[12].self_attn.v_proj.weight                                "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/micrlhf-progress/main.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39mLoading\u001b[39m\u001b[39m\"\u001b[39m, k, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m og \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mllama.\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m weight \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mdevice_put(weight\u001b[39m.\u001b[39;49mastype(og\u001b[39m.\u001b[39;49mdtype), device\u001b[39m=\u001b[39mog\u001b[39m.\u001b[39msharding)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(k, weight)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "print()\n",
    "for filename in [\n",
    "    \"models/Llama-2-7b-hf/model-00001-of-00002.safetensors\",\n",
    "    \"models/Llama-2-7b-hf/model-00002-of-00002.safetensors\",\n",
    "]:\n",
    "    with safe_open(\n",
    "        filename,\n",
    "        framework=\"numpy\",\n",
    "        device=\"cpu\",\n",
    "    ) as f:\n",
    "        for k in f.keys():\n",
    "            weight = f.get_tensor(k)\n",
    "            if (\n",
    "                k.endswith(\".weight\")\n",
    "                and not k.endswith(\"embed_tokens.weight\")\n",
    "                and not k.endswith(\"norm.weight\")\n",
    "                # and not k.endswith(\"lm_head.weight\")\n",
    "            ):\n",
    "                weight = weight.T\n",
    "            re_sult = re.search(r\"layers\\.([0-9]+)\", k)\n",
    "            try:\n",
    "                k = (\n",
    "                    k[: re_sult.span()[0]]\n",
    "                    + f\"layers[{re_sult.group(1)}]\"\n",
    "                    + k[re_sult.span()[1] :]\n",
    "                )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            print(\"\\r\" + \" \" * 80, end=\"\")\n",
    "            print(\"\\rLoading\", k, end=\"\")\n",
    "            og = eval(f\"llama.{k}\")\n",
    "            weight = jax.device_put(weight.astype(og.dtype), device=og.sharding)\n",
    "            llama = eval(f\"eqx.tree_at(lambda l: l.{k}, llama, weight)\")\n",
    "print()\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extract_state' from 'state_util' (/home/neverix/micrlhf-progress/state_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/micrlhf-progress/main.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstate_util\u001b[39;00m \u001b[39mimport\u001b[39;00m extract_state, statify\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mregister_pytree_node(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         jmp\u001b[39m.\u001b[39mPolicy,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m policy: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m _, tup: jmp\u001b[39m.\u001b[39mPolicy(\u001b[39m*\u001b[39mtup),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/micrlhf-progress/main.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extract_state' from 'state_util' (/home/neverix/micrlhf-progress/state_util.py)"
     ]
    }
   ],
   "source": [
    "from state_util import extract_state, statify\n",
    "\n",
    "\n",
    "try:\n",
    "    jax.tree_util.register_pytree_node(\n",
    "        jmp.Policy,\n",
    "        lambda policy: (\n",
    "            (policy.param_dtype, policy.compute_dtype, policy.output_dtype),\n",
    "            None,\n",
    "        ),\n",
    "        lambda _, tup: jmp.Policy(*tup),\n",
    "    )\n",
    "except ValueError:\n",
    "    pass\n",
    "try:\n",
    "    jax.tree_util.register_pytree_node(\n",
    "        jax._src.numpy.lax_numpy._ScalarMeta, lambda x: (tuple(), x), lambda _, x: x\n",
    "    )\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "\n",
    "def tree_multiflat(tree):\n",
    "    if isinstance(tree, (int, float, bool, str, np.ndarray, jax.Array, jmp.Policy)):\n",
    "        return []\n",
    "    leaves, treedef = jax.tree_flatten(tree, is_leaf=lambda x: x is not tree)\n",
    "    if not leaves:\n",
    "        return [tree]\n",
    "    if any(x is tree for x in leaves):\n",
    "        return\n",
    "    leaves = [tree_multiflat(leaf) for leaf in leaves]\n",
    "    return [tree] + leaves\n",
    "\n",
    "\n",
    "# short for multi-level map\n",
    "def tree_mlm(fn, tree):\n",
    "    if not isinstance(tree, eqx.Module):\n",
    "        return tree\n",
    "    leaves, treedef = jax.tree_util.tree_flatten_with_path(\n",
    "        tree, is_leaf=lambda x: x is not tree\n",
    "    )\n",
    "    if not leaves:\n",
    "        return tree\n",
    "    if any(x is tree for x in leaves):\n",
    "        return\n",
    "    leaves = [fn(path, tree_mlm(fn, leaf)) for path, leaf in leaves]\n",
    "    return jax.tree_util.tree_unflatten(treedef, leaves)\n",
    "\n",
    "\n",
    "class DebugWrapper(eqx.Module):\n",
    "    index: eqx.nn.StateIndex\n",
    "    module: eqx.Module\n",
    "    path: str\n",
    "\n",
    "    def __init__(self, module, path):\n",
    "        self.module = module\n",
    "        self.index = eqx.nn.StateIndex(jnp.empty(module.out_shape))\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        _, _, state = extract_state(args, kwargs)\n",
    "        output = self.module(*args, **kwargs)\n",
    "        state = state.set(self.index, (args, kwargs, output))\n",
    "        return output, state\n",
    "\n",
    "    def __hasattr__(self, attr):\n",
    "        return hasattr(self.module, attr)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.module, attr)\n",
    "\n",
    "\n",
    "def debugify_model(model_base):\n",
    "    def debugify(path, leaf):\n",
    "        if not isinstance(leaf, eqx.Module):\n",
    "            return leaf\n",
    "        if not hasattr(leaf, \"__call__\"):\n",
    "            return leaf\n",
    "\n",
    "        path = \"\".join(map(str, path))\n",
    "        return DebugWrapper(leaf, path)\n",
    "\n",
    "    model = tree_mlm(debugify, model_base)\n",
    "    model, state_base = statify(model)\n",
    "    \n",
    "    def new_model(*args, **kwargs):\n",
    "        output, state = model(*args, **{**kwargs, \"state\": state_base})\n",
    "\n",
    "        debugs = [x for x in tree_multiflat(model) if isinstance(x, DebugWrapper)]\n",
    "        debug = {db.path: state.get(db.index) for db in debugs}\n",
    "\n",
    "        return output, debug\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "llama_debug = jax.vmap(debugify_model(llama))\n",
    "shmoogle_smi()\n",
    "\n",
    "with mesh:\n",
    "    input_ids = [\n",
    "        tokenizer.encode(x, bos=True, eos=False)\n",
    "        for x in [\"Hello world\", \"This is a test\"]\n",
    "    ]\n",
    "    input_ids = [x + [0] * (128 - len(x)) for x in input_ids]\n",
    "    ids = jnp.asarray(input_ids)\n",
    "    ids = jax.device_put(ids, NamedSharding(mesh, spec=PartitionSpec(\"dp\", None)))\n",
    "    result = llama_debug(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_llama = transformers.LlamaModel.from_pretrained(\"models/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def make_torch_hook(name):\n",
    "    def torch_hook(module, input, output):\n",
    "        print(f\"Module called: {name} {module.__class__}\")\n",
    "        for arg in input:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                print(\"Input:\", arg.shape, arg.dtype, str(arg)[:100])\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            print(\"Output:\", output.shape, output.dtype, str(output)[:100])\n",
    "        return output\n",
    "\n",
    "    return torch_hook\n",
    "\n",
    "\n",
    "for name, module in reference_llama.named_modules():\n",
    "    module._forward_hooks.clear()\n",
    "    module.register_forward_hook(make_torch_hook(name))\n",
    "\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "reference_llama(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
