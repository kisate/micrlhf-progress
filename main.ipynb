{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mem usage: 0.0 GB out of 128 GB\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "\n",
    "def shmoogle_smi():\n",
    "    jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    pprof_path = \"/usr/local/go/pkg/tool/linux_amd64/pprof\"\n",
    "    out = subprocess.run([pprof_path, \"-top\", \"memory.prof\"], stdout=subprocess.PIPE)\n",
    "    stdout = out.stdout.decode(\"utf-8\")\n",
    "    re_sult = re.search(\n",
    "        r\"Showing nodes accounting for (\\d+(?:\\.\\d+)?)([MG]B)?, (\\d+(?:\\.\\d+)?)% of (\\d+(?:\\.\\d+)?)([MG]B)? total\",\n",
    "        stdout,\n",
    "    )\n",
    "    multiplier = 1 / 1000 if re_sult.group(5) == \"MB\" else 1\n",
    "    total_mem_usage = float(re_sult.group(4))\n",
    "    print(\n",
    "        \"Total mem usage:\",\n",
    "        total_mem_usage * multiplier,\n",
    "        \"GB\",\n",
    "        \"out of\",\n",
    "        16 * len(jax.devices()),\n",
    "        \"GB\",\n",
    "    )\n",
    "\n",
    "\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "from llama2_model import LLaMA\n",
    "\n",
    "import equinox as eqx\n",
    "import re\n",
    "from safetensors import safe_open\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
    "import jax.numpy as jnp\n",
    "import transformers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 15043, 3186, 29991]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\"models/Llama-2-7b-hf/tokenizer.model\")\n",
    "input_ids = tokenizer.encode(\"Hello world!\", bos=True, eos=False)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LLaMA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created LLaMA.\n",
      "Total mem usage: 29.99 GB out of 128 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    }
   ],
   "source": [
    "num_devices = len(jax.devices())\n",
    "mesh = Mesh(np.array(jax.devices()).reshape(-1, 4), axis_names=(\"dp\", \"mp\"))\n",
    "policy = jmp.get_policy(\"p=bf16,c=bf16,o=bf16\")\n",
    "print(\"Creating LLaMA...\")\n",
    "llama = LLaMA(mesh, policy=policy)\n",
    "print(\"Created LLaMA.\")\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "Loading model.norm.weight                                                       \n",
      "Total mem usage: 29.99 GB out of 128 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "print()\n",
    "for filename in [\n",
    "    \"models/Llama-2-7b-hf/model-00001-of-00002.safetensors\",\n",
    "    \"models/Llama-2-7b-hf/model-00002-of-00002.safetensors\",\n",
    "]:\n",
    "    with safe_open(\n",
    "        filename,\n",
    "        framework=\"numpy\",\n",
    "        device=\"cpu\",\n",
    "    ) as f:\n",
    "        for k in f.keys():\n",
    "            weight = f.get_tensor(k)\n",
    "            if (\n",
    "                k.endswith(\".weight\")\n",
    "                and not k.endswith(\"embed_tokens.weight\")\n",
    "                and not k.endswith(\"norm.weight\")\n",
    "                # and not k.endswith(\"lm_head.weight\")\n",
    "            ):\n",
    "                weight = weight.T\n",
    "            re_sult = re.search(r\"layers\\.([0-9]+)\", k)\n",
    "            try:\n",
    "                k = (\n",
    "                    k[: re_sult.span()[0]]\n",
    "                    + f\"layers[{re_sult.group(1)}]\"\n",
    "                    + k[re_sult.span()[1] :]\n",
    "                )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            print(\"\\r\" + \" \" * 80, end=\"\")\n",
    "            print(\"\\rLoading\", k, end=\"\")\n",
    "            og = eval(f\"llama.{k}\")\n",
    "            weight = jax.device_put(weight.astype(og.dtype), device=og.sharding)\n",
    "            llama = eval(f\"eqx.tree_at(lambda l: l.{k}, llama, weight)\")\n",
    "print()\n",
    "shmoogle_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main binary filename not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mem usage: 30.27 GB out of 128 GB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m ids \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39masarray(input_ids)\n\u001b[1;32m    110\u001b[0m ids \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mdevice_put(ids, NamedSharding(mesh, spec\u001b[38;5;241m=\u001b[39mPartitionSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)))\n\u001b[0;32m--> 111\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllama_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/api.py:1249\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1247\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1249\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[0;32mIn[9], line 93\u001b[0m, in \u001b[0;36mdebugify_model.<locals>.new_model\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_model\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 93\u001b[0m     output, state, cache \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, cache\n",
      "File \u001b[0;32m~/micrlhf-progress/llama2_model.py:405\u001b[0m, in \u001b[0;36mLLaMA.__call__\u001b[0;34m(self, x, state, cache)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, state: eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mState, cache: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 405\u001b[0m     embeds, state, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m))(embeds, state, cache)\n",
      "Cell \u001b[0;32mIn[9], line 65\u001b[0m, in \u001b[0;36mDebugWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     64\u001b[0m     _, _, cache \u001b[38;5;241m=\u001b[39m extract_cache(args, kwargs)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;241m*\u001b[39moutput, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     cache \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcache, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath: (args, kwargs, output)}\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output) \u001b[38;5;241m+\u001b[39m (cache,)\n",
      "File \u001b[0;32m~/micrlhf-progress/llama2_model.py:365\u001b[0m, in \u001b[0;36mLLaMAModel.__call__\u001b[0;34m(self, x, state, cache)\u001b[0m\n\u001b[1;32m    363\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mcast_to_compute(x)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 365\u001b[0m     x, state, cache \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# x = jax.lax.scan(lambda carry, layer: layer(carry), x, self.layers)[0]\u001b[39;00m\n\u001b[1;32m    367\u001b[0m x, state, cache \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m), out_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m))(x, state, cache)\n",
      "Cell \u001b[0;32mIn[9], line 65\u001b[0m, in \u001b[0;36mDebugWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     64\u001b[0m     _, _, cache \u001b[38;5;241m=\u001b[39m extract_cache(args, kwargs)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;241m*\u001b[39moutput, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     cache \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcache, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath: (args, kwargs, output)}\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output) \u001b[38;5;241m+\u001b[39m (cache,)\n",
      "File \u001b[0;32m~/micrlhf-progress/llama2_model.py:300\u001b[0m, in \u001b[0;36mLLaMALayer.__call__\u001b[0;34m(self, x, state, cache)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, state: eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mState, cache: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    299\u001b[0m     y, state, cache \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm)(x, state, cache)\n\u001b[0;32m--> 300\u001b[0m     y, state, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y\n\u001b[1;32m    302\u001b[0m     y, state, cache \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm)(x, state, cache)\n",
      "Cell \u001b[0;32mIn[9], line 65\u001b[0m, in \u001b[0;36mDebugWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     64\u001b[0m     _, _, cache \u001b[38;5;241m=\u001b[39m extract_cache(args, kwargs)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;241m*\u001b[39moutput, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     cache \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcache, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath: (args, kwargs, output)}\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output) \u001b[38;5;241m+\u001b[39m (cache,)\n",
      "File \u001b[0;32m~/micrlhf-progress/llama2_model.py:247\u001b[0m, in \u001b[0;36mSelfAttention.__call__\u001b[0;34m(self, x, state, cache, attention_mask)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, state: eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mState, cache: \u001b[38;5;28mdict\u001b[39m, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# for now, regular attention\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mcast_to_compute(x)\n\u001b[0;32m--> 247\u001b[0m     q, state, cache \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     k, state, cache \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj)(x, state, cache)\n\u001b[1;32m    249\u001b[0m     v, state, cache \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj)(x, state, cache)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/api.py:1249\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1247\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1249\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/linear_util.py:206\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m gen, out_store \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;66;03m# As above does for the first half of the transformation, exceptions\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;66;03m# raised in the second half of the transformation also require us to\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;66;03m# clean up references here.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/interpreters/batching.py:638\u001b[0m, in \u001b[0;36m_batch_inner\u001b[0;34m(axis_size, out_dim_dests, main, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    636\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m in_tracers, {}\n\u001b[1;32m    637\u001b[0m out_dim_dests \u001b[38;5;241m=\u001b[39m out_dim_dests() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(out_dim_dests) \u001b[38;5;28;01melse\u001b[39;00m out_dim_dests\n\u001b[0;32m--> 638\u001b[0m out_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_elt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim_dests\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m out_vals\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/interpreters/batching.py:262\u001b[0m, in \u001b[0;36mfrom_elt\u001b[0;34m(trace, axis_size, x, spec)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler:\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m handler(partial(from_elt, trace), axis_size, x, spec)\n\u001b[0;32m--> 262\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m val, bdim \u001b[38;5;241m=\u001b[39m x_\u001b[38;5;241m.\u001b[39mval, x_\u001b[38;5;241m.\u001b[39mbatch_dim\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(bdim) \u001b[38;5;129;01mis\u001b[39;00m RaggedAxis:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:479\u001b[0m, in \u001b[0;36mTrace.full_raise\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfull_raise\u001b[39m(\u001b[38;5;28mself\u001b[39m, val) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TracerType:\n\u001b[0;32m--> 479\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdimension_as_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# Used for shape_poly._DimPolynomial\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     val \u001b[38;5;241m=\u001b[39m val\u001b[38;5;241m.\u001b[39mdimension_as_value()\n\u001b[1;32m    481\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Tracer):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:744\u001b[0m, in \u001b[0;36mTracer.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maval\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m   attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m, name)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    746\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    747\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    748\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/interpreters/batching.py:333\u001b[0m, in \u001b[0;36mBatchTracer.aval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 333\u001b[0m   aval \u001b[38;5;241m=\u001b[39m raise_to_shaped(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dim \u001b[38;5;129;01mis\u001b[39;00m not_mapped:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aval\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:1429\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_aval\u001b[39m(x):\n\u001b[1;32m   1428\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tracer):\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\n\u001b[1;32m   1430\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/interpreters/batching.py:333\u001b[0m, in \u001b[0;36mBatchTracer.aval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 333\u001b[0m   aval \u001b[38;5;241m=\u001b[39m \u001b[43mraise_to_shaped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dim \u001b[38;5;129;01mis\u001b[39;00m not_mapped:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aval\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:1891\u001b[0m, in \u001b[0;36mraise_to_shaped\u001b[0;34m(aval, weak_type)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m typ \u001b[38;5;129;01min\u001b[39;00m aval_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__mro__\u001b[39m:\n\u001b[1;32m   1890\u001b[0m   handler \u001b[38;5;241m=\u001b[39m raise_to_shaped_mappings\u001b[38;5;241m.\u001b[39mget(typ)\n\u001b[0;32m-> 1891\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m handler: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(aval))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:1898\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(aval, weak_type)\u001b[0m\n\u001b[1;32m   1891\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handler: \u001b[38;5;28;01mreturn\u001b[39;00m handler(aval, weak_type)\n\u001b[1;32m   1892\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(aval))\n\u001b[1;32m   1894\u001b[0m raise_to_shaped_mappings : \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m, Callable] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1895\u001b[0m   AbstractToken: \u001b[38;5;28;01mlambda\u001b[39;00m aval, _: aval,\n\u001b[1;32m   1896\u001b[0m   Bot: \u001b[38;5;28;01mlambda\u001b[39;00m aval, _: aval,\n\u001b[1;32m   1897\u001b[0m   UnshapedArray: \u001b[38;5;28;01mlambda\u001b[39;00m aval, _: aval,\n\u001b[0;32m-> 1898\u001b[0m   ShapedArray: \u001b[38;5;28;01mlambda\u001b[39;00m aval, weak_type: \u001b[43mShapedArray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m      \u001b[49m\u001b[43maval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_shape\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1900\u001b[0m   DConcreteArray: \u001b[38;5;28;01mlambda\u001b[39;00m aval, weak_type: DShapedArray(\n\u001b[1;32m   1901\u001b[0m       aval\u001b[38;5;241m.\u001b[39mshape, aval\u001b[38;5;241m.\u001b[39mdtype, weak_type),\n\u001b[1;32m   1902\u001b[0m }\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;66;03m### Operations on shapes and dimension sizes.\u001b[39;00m\n\u001b[1;32m   1906\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInconclusiveDimensionOperation\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:1589\u001b[0m, in \u001b[0;36mShapedArray.__init__\u001b[0;34m(self, shape, dtype, weak_type, named_shape)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, dtype, weak_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, named_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m \u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m _dtype_object(dtype)\n\u001b[1;32m   1591\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweak_type \u001b[38;5;241m=\u001b[39m weak_type\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:2048\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Canonicalizes and checks for errors in a user-provided shape value.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m \n\u001b[1;32m   2041\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;124;03m  A tuple of canonical dimension values.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2048\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munsafe_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_canonicalize_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/core.py:2022\u001b[0m, in \u001b[0;36m_canonicalize_dimension\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m   2019\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(d, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension_as_value\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m d\u001b[38;5;241m.\u001b[39mdimension_as_value()\n\u001b[1;32m   2020\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mindex(d)\n\u001b[0;32m-> 2022\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_canonicalize_dimension\u001b[39m(dim: DimSize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DimSize:\n\u001b[1;32m   2023\u001b[0m   \u001b[38;5;66;03m# Dimensions are most commonly integral (by far), so we check that first.\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mindex(dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from state_util import extract_arg, statify, dummy_caching, dummy_stateful\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "extract_state = partial(extract_arg, arg_name=\"state\", index=-2)\n",
    "extract_cache = partial(extract_arg, arg_name=\"cache\", index=-1)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     jax.tree_util.register_pytree_node(\n",
    "#         jmp.Policy,\n",
    "#         lambda policy: (\n",
    "#             vars(policy),\n",
    "#             None,\n",
    "#         ),\n",
    "#         lambda _, dct: jmp.Policy(**dct),\n",
    "#     )\n",
    "# except ValueError:\n",
    "#     pass\n",
    "try:\n",
    "    jax.tree_util.register_pytree_node(\n",
    "        jax._src.numpy.lax_numpy._ScalarMeta, lambda x: (tuple(), x), lambda _, x: x\n",
    "    )\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "\n",
    "def tree_multiflat(tree):\n",
    "    if isinstance(tree, (int, float, bool, str, np.ndarray, jax.Array, jmp.Policy)):\n",
    "        return []\n",
    "    leaves, treedef = jax.tree_flatten(tree, is_leaf=lambda x: x is not tree)\n",
    "    if not leaves:\n",
    "        return [tree]\n",
    "    if any(x is tree for x in leaves):\n",
    "        return\n",
    "    leaves = [tree_multiflat(leaf) for leaf in leaves]\n",
    "    return [tree] + leaves\n",
    "\n",
    "\n",
    "# short for multi-level map\n",
    "def tree_mlm(fn, tree, prefix=()):\n",
    "    if not isinstance(tree, (eqx.Module, list)):\n",
    "        return tree\n",
    "    leaves, treedef = jax.tree_util.tree_flatten_with_path(\n",
    "        tree, is_leaf=lambda x: x is not tree\n",
    "    )\n",
    "    if not leaves:\n",
    "        return tree\n",
    "    if any(x is tree for x in leaves):\n",
    "        return\n",
    "    leaves = [fn(prefix+path, tree_mlm(fn, leaf, prefix=prefix+path)) for path, leaf in leaves]\n",
    "    return jax.tree_util.tree_unflatten(treedef, leaves)\n",
    "\n",
    "\n",
    "class DebugWrapper(eqx.Module):\n",
    "    module: eqx.Module\n",
    "    path: str\n",
    "\n",
    "    def __init__(self, module, path):\n",
    "        self.module = module\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        _, _, cache = extract_cache(args, kwargs)\n",
    "        *output, cache = self.module(*args, **kwargs)\n",
    "        cache = {**cache, self.path: (args, kwargs, output)}\n",
    "        return tuple(output) + (cache,)\n",
    "\n",
    "    def __hasattr__(self, attr):\n",
    "        return hasattr(self.module, attr)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.module, attr)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.module)\n",
    "\n",
    "\n",
    "def debugify_model(model_base):\n",
    "    def debugify(path, leaf):\n",
    "        if not isinstance(leaf, (eqx.Module, list)):\n",
    "            return leaf\n",
    "        if not hasattr(leaf, \"__call__\"):\n",
    "            return leaf\n",
    "\n",
    "        path = \"\".join(map(str, path))\n",
    "        return DebugWrapper(leaf, path)\n",
    "\n",
    "    model = tree_mlm(debugify, model_base)\n",
    "    model, state_base = statify(model)\n",
    "    \n",
    "    def new_model(*args, **kwargs):\n",
    "        output, state, cache = model(*args, **{**kwargs, \"state\": state_base, \"cache\": {}})\n",
    "\n",
    "        return output, cache\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "llama_debug = jax.vmap(debugify_model(llama))\n",
    "shmoogle_smi()\n",
    "\n",
    "with mesh:\n",
    "    input_ids = [\n",
    "        tokenizer.encode(x, bos=True, eos=False)\n",
    "        for x in [\"Hello world\", \"This is a test\"]\n",
    "    ]\n",
    "    input_ids = [x + [0] * (128 - len(x)) for x in input_ids]\n",
    "    ids = jnp.asarray(input_ids)\n",
    "    ids = jax.device_put(ids, NamedSharding(mesh, spec=PartitionSpec(\"dp\", None)))\n",
    "    result = llama_debug(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reference_llama \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/Llama-2-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/modeling_utils.py:3236\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 3236\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3238\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:823\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:634\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    630\u001b[0m     LlamaAttention(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flash_attn_2_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m LlamaFlashAttention2(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m    633\u001b[0m )\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:237\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn \u001b[38;5;241m=\u001b[39m ACT2FN[config\u001b[38;5;241m.\u001b[39mhidden_act]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/modules/linear.py:109\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/init.py:459\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    457\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reference_llama = transformers.LlamaModel.from_pretrained(\"models/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def make_torch_hook(name):\n",
    "    def torch_hook(module, input, output):\n",
    "        print(f\"Module called: {name} {module.__class__}\")\n",
    "        for arg in input:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                print(\"Input:\", arg.shape, arg.dtype, str(arg)[:100])\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            print(\"Output:\", output.shape, output.dtype, str(output)[:100])\n",
    "        return output\n",
    "\n",
    "    return torch_hook\n",
    "\n",
    "\n",
    "for name, module in reference_llama.named_modules():\n",
    "    module._forward_hooks.clear()\n",
    "    module.register_forward_hook(make_torch_hook(name))\n",
    "\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "reference_llama(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
