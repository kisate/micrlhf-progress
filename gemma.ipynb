{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.embeddings [2048, 256000] {'vocabulary': 256000, 'embedding': 2048} q8_0\n",
      "blocks.0.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.0.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.0.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.0.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.0.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.0.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.0.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.0.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.0.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.1.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.1.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.1.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.1.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.1.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.1.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.1.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.1.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.1.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.2.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.2.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.2.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.2.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.2.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.2.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.2.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.2.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.2.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.3.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.3.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.3.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.3.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.3.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.3.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.3.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.3.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.3.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.4.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.4.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.4.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.4.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.4.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.4.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.4.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.4.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.4.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.5.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.5.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.5.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.5.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.5.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.5.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.5.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.5.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.5.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.6.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.6.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.6.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.6.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.6.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.6.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.6.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.6.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.6.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.7.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.7.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.7.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.7.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.7.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.7.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.7.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.7.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.7.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.8.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.8.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.8.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.8.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.8.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.8.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.8.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.8.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.8.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.9.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.9.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.9.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.9.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.9.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.9.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.9.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.9.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.9.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.10.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.10.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.10.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.10.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.10.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.10.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.10.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.10.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.10.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.11.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.11.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.11.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.11.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.11.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.11.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.11.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.11.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.11.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.12.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.12.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.12.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.12.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.12.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.12.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.12.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.12.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.12.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.13.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.13.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.13.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.13.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.13.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.13.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.13.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.13.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.13.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.14.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.14.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.14.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.14.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.14.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.14.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.14.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.14.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.14.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.15.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.15.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.15.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.15.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.15.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.15.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.15.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.15.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.15.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.16.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.16.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.16.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.16.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.16.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.16.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.16.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.16.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.16.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "blocks.17.pre_attn_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.17.attn.query.weights [2048, 2048] {'embedding': 2048, 'kv_heads': 1, 'q_rep': 8, 'projection': 256} q8_0\n",
      "blocks.17.attn.key.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.17.attn.value.weights [2048, 256] {'embedding': 2048, 'kv_heads': 1, 'projection': 256} q8_0\n",
      "blocks.17.attn.output.weights [2048, 2048] {'kv_heads': 1, 'q_rep': 8, 'projection': 256, 'embedding': 2048} q8_0\n",
      "blocks.17.pre_mlp_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "blocks.17.mlp.gate_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.17.mlp.up_proj.weights [2048, 16384] {'embedding': 2048, 'neurons': 16384} q8_0\n",
      "blocks.17.mlp.out_proj.weights [16384, 2048] {'neurons': 16384, 'embedding': 2048} q8_0\n",
      "final_norm.scale.weights [2048] {'embedding': 2048} fp32\n",
      "unembed.embeddings [2048, 256000] {'vocabulary': 256000, 'embedding': 2048} q8_0\n"
     ]
    }
   ],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(\"models/gemma-2b.gguf\", device_map=\"auto\",\n",
    "                                         from_type=\"gemma\", load_eager=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alpindale/gemma-2b\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba177bc53db45b1b17c98770f0f33c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"alpindale/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 2048]) tensor([[[ 5.3917,  0.8673, -1.4363,  ..., -0.2969,  0.0157, -0.4033],\n",
      "         [10.3856, -2.8726, -3.0936,  ..., -0.2983,  1.9003, -3.1157],\n",
      "         [13.4350, -2.3754,  0.7568,  ..., -0.0687,  2.4528, -1.1214],\n",
      "         ...,\n",
      "         [10.5182, -1.1270, -4.5299,  ..., -0.3439,  2.0329,  0.9723],\n",
      "         [15.4680, -1.9224,  1.9666,  ...,  1.8672,  2.1324, -2.6296],\n",
      "         [12.1092, -0.8121,  2.5301,  ..., -1.1656,  1.1546, -0.0511]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_234c7815c14f4a2e972744205c577d24\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_626ed5f15d1540d785520ad43c629d6c\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_626ed5f15d1540d785520ad43c629d6c\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_234c7815c14f4a2e972744205c577d24\"><script> (()=>{ const output = document.getElementById(\"output_234c7815c14f4a2e972744205c577d24\"); const dest = document.getElementById(\"output_dest_234c7815c14f4a2e972744205c577d24\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "tensor([[[-26.5950, -13.8833, -18.2747,  ..., -21.2892, -23.2392, -26.5799],\n",
       "         [-42.4406, -33.3739, -47.8576,  ..., -42.1095, -46.7014, -42.5487],\n",
       "         [-42.5846, -30.0222, -34.0748,  ..., -40.6030, -38.9625, -42.6937],\n",
       "         ...,\n",
       "         [-41.7852, -19.4810, -38.3410,  ..., -38.2935, -41.6302, -41.8573],\n",
       "         [-39.3097, -18.4143, -34.3758,  ..., -36.4977, -40.6678, -39.3800],\n",
       "         [-42.2921, -23.0559, -36.2486,  ..., -38.2521, -37.0666, -42.3374]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "for m in model.modules():\n",
    "    m._forward_hooks = OrderedDict()\n",
    "model.model.layers[0].register_forward_hook(lambda self, input, output: print(input[0]))\n",
    "model(torch.LongTensor(tokens).unsqueeze(0)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_562538185b1342609f8406fc162558b6\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_a067bffc39b14e8082cb6a65df918709\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_a067bffc39b14e8082cb6a65df918709\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_562538185b1342609f8406fc162558b6\"><script> (()=>{ const output = document.getElementById(\"output_562538185b1342609f8406fc162558b6\"); const dest = document.getElementById(\"output_dest_562538185b1342609f8406fc162558b6\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "tensor([[[ 0.1191,  0.0192, -0.0317,  ..., -0.0066,  0.0003, -0.0089],\n",
       "         [ 0.2295, -0.0635, -0.0684,  ..., -0.0066,  0.0420, -0.0688],\n",
       "         [ 0.2969, -0.0525,  0.0167,  ..., -0.0015,  0.0542, -0.0248],\n",
       "         ...,\n",
       "         [ 0.2324, -0.0249, -0.1001,  ..., -0.0076,  0.0449,  0.0215],\n",
       "         [ 0.3418, -0.0425,  0.0435,  ...,  0.0413,  0.0471, -0.0581],\n",
       "         [ 0.2676, -0.0179,  0.0559,  ..., -0.0258,  0.0255, -0.0011]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.model.embed_tokens(torch.LongTensor(tokens).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_8443222e8460496b82b69719a0d3d46a\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_60f5196210724274ae9deb7e51c155a6\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_60f5196210724274ae9deb7e51c155a6\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_2405456c7abb48ddaa2596d7174af520\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_2405456c7abb48ddaa2596d7174af520\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_8443222e8460496b82b69719a0d3d46a\"><script> (()=>{ const output = document.getElementById(\"output_8443222e8460496b82b69719a0d3d46a\"); const dest = document.getElementById(\"output_dest_8443222e8460496b82b69719a0d3d46a\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "# jax.Array bfloat16(10, 2048) ≈0.00042 ±0.16 [≥-1e+01, ≤6.3] zero:276 nonzero:20_204\n",
       "  Array([[0.119141, 0.0187988, -0.0319824, ..., -0.00628662, 0,\n",
       "          -0.00628662],\n",
       "         [0.229492, -0.0639648, -0.0683594, ..., -0.00872803, 0.0437012,\n",
       "          -0.0698242],\n",
       "         [0.296875, -0.0512695, 0.0163574, ..., 0, 0.052002, -0.026001],\n",
       "         ...,\n",
       "         [0.232422, -0.0256348, -0.100586, ..., -0.00540161, 0.0432129,\n",
       "          0.0216064],\n",
       "         [0.341797, -0.0429688, 0.0429688, ..., 0.0424805, 0.0478516,\n",
       "          -0.0583496],\n",
       "         [0.267578, -0.0189209, 0.0568848, ..., -0.0263672, 0.0263672, 0]], dtype=bfloat16)\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama.select().at_instances_of(pz.nn.EmbeddingLookup).get_sequence()[0](inputs.tokens).unwrap(\"batch\", \"seq\", \"embedding\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_7f27ba293dd246169e46477283c69e98\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_75417f6224c84770a1ecc3eaf4abf5d9\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_75417f6224c84770a1ecc3eaf4abf5d9\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_65d275ba0b6b4fd28d16f047de85b4d1\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_65d275ba0b6b4fd28d16f047de85b4d1\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_7f27ba293dd246169e46477283c69e98\"><script> (()=>{ const output = document.getElementById(\"output_7f27ba293dd246169e46477283c69e98\"); const dest = document.getElementById(\"output_dest_7f27ba293dd246169e46477283c69e98\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "# jax.Array bfloat16(10, 2048) ≈0.00042 ±0.16 [≥-1e+01, ≤6.3] zero:276 nonzero:20_204\n",
       "  Array([[0.119141, 0.0187988, -0.0319824, ..., -0.00628662, 0,\n",
       "          -0.00628662],\n",
       "         [0.229492, -0.0639648, -0.0683594, ..., -0.00872803, 0.0437012,\n",
       "          -0.0698242],\n",
       "         [0.296875, -0.0512695, 0.0163574, ..., 0, 0.052002, -0.026001],\n",
       "         ...,\n",
       "         [0.232422, -0.0256348, -0.100586, ..., -0.00540161, 0.0432129,\n",
       "          0.0216064],\n",
       "         [0.341797, -0.0429688, 0.0429688, ..., 0.0424805, 0.0478516,\n",
       "          -0.0583496],\n",
       "         [0.267578, -0.0189209, 0.0568848, ..., -0.0263672, 0.0263672, 0]], dtype=bfloat16)\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from micrlhf.llama import LlamaBlock\n",
    "get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "    pz.nn.Sequential([\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "        x\n",
    "    ])\n",
    ")\n",
    "get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "token_array = jnp.asarray([tokens] * 4)\n",
    "token_array = jax.device_put(token_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "token_array = pz.nx.wrap(token_array, \"batch\", \"seq\")\n",
    "inputs = llama.inputs.from_basic_segments(token_array)\n",
    "get_resids(inputs)[1][0].value.unwrap(\"batch\", \"seq\", \"embedding\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b38af3f46c44a2b8d4e022d79dfc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmicrlhf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[0;32m----> 2\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite me a poem about Machine Learning.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m texts\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/sampling.py:89\u001b[0m, in \u001b[0;36msample\u001b[0;34m(llama, tokenizer, prompt, batch_size, max_seq_len, pad_token_id, do_sample, return_model)\u001b[0m\n\u001b[1;32m     86\u001b[0m advanced, tokens, key \u001b[38;5;241m=\u001b[39m sample_logits(logits, tokens, cache, key, do_sample\u001b[38;5;241m=\u001b[39mdo_sample)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m (bar \u001b[38;5;241m:=\u001b[39m trange(max_seq_len)):\n\u001b[0;32m---> 89\u001b[0m     advanced, tokens, cache, key \u001b[38;5;241m=\u001b[39m \u001b[43msample_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama_cached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mbase_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# bar.set_description(tokenizer.decode(tokens.untag(\"batch\", \"seq\").data_array[0]))\u001b[39;00m\n\u001b[1;32m     93\u001b[0m texts \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(sequence) \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39muntag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdata_array]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/pjit.py:304\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 304\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m      \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    307\u001b[0m   maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    308\u001b[0m       executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    309\u001b[0m       jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/pjit.py:181\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m   args_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39minit_states, \u001b[38;5;241m*\u001b[39margs_flat]\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    183\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/core.py:2789\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2785\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2786\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2787\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2788\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/core.py:391\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    390\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 391\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/core.py:879\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    877\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/pjit.py:1525\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d]\n\u001b[1;32m   1523\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[1;32m   1524\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshard_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/pjit.py:1508\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_impl_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1508\u001b[0m   out_flat, compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1514\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1515\u001b[0m       compiled, tree_structure(out_flat), args, out_flat, [], jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m   1516\u001b[0m       jaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1517\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out_flat, fastpath_data\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/pjit.py:1438\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pjit_call_impl_python\u001b[39m(\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;241m*\u001b[39margs, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts,\n\u001b[1;32m   1431\u001b[0m     resource_env, donated_invars, name, keep_unused, inline):\n\u001b[1;32m   1432\u001b[0m   \u001b[38;5;28;01mglobal\u001b[39;00m _most_recent_pjit_call_executable\n\u001b[1;32m   1434\u001b[0m   compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m      \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m   _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mweak_key_dict[jaxpr] \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1441\u001b[0m   \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2363\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, compiler_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MeshExecutable:\n\u001b[1;32m   2362\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2363\u001b[0m     executable \u001b[38;5;241m=\u001b[39m \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiler_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2367\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;241m=\u001b[39m executable\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2860\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2857\u001b[0m       mesh \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mmesh  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2858\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 2860\u001b[0m xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_options_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n\u001b[1;32m   2867\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2678\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2673\u001b[0m opts\u001b[38;5;241m.\u001b[39mallow_spmd_sharding_propagation_to_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(allow_prop_to_outputs)\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\n\u001b[1;32m   2676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{elapsed_time}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2677\u001b[0m     fun_name\u001b[38;5;241m=\u001b[39mname, event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2678\u001b[0m   xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2679\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/compiler.py:330\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    320\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _compile_and_write_autotune_config(\n\u001b[1;32m    321\u001b[0m       backend,\n\u001b[1;32m    322\u001b[0m       computation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m       cache_key,\n\u001b[1;32m    328\u001b[0m   )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/compiler.py:501\u001b[0m, in \u001b[0;36m_compile_and_write_cache\u001b[0;34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_and_write_cache\u001b[39m(\n\u001b[1;32m    493\u001b[0m     backend: xc\u001b[38;5;241m.\u001b[39mClient,\n\u001b[1;32m    494\u001b[0m     computation: ir\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    499\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xc\u001b[38;5;241m.\u001b[39mLoadedExecutable:\n\u001b[1;32m    500\u001b[0m   start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 501\u001b[0m   executable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m   compile_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    505\u001b[0m   _cache_write(\n\u001b[1;32m    506\u001b[0m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[1;32m    507\u001b[0m   )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py:335\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/compiler.py:237\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    233\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from micrlhf.sampling import sample\n",
    "texts = sample(llama, tokenizer, \"Write me a poem about Machine Learning.\",\n",
    "               batch_size=4, do_sample=True)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
